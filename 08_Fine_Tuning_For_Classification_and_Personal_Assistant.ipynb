{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZMPSq1gIZQz"
      },
      "source": [
        "# **IMPLEMENTING A GPT MODEL FROM SCRATCH TO GENERATE TEXT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzsQklDLIZQz"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "m17xR3rfUmTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02GtSAIsIZQz"
      },
      "source": [
        "## **GPT ARCHITECTURE PART 1: DUMMY GPT MODEL CLASS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PHnrEzGIZQz"
      },
      "source": [
        "Step 1: Use a placeholder for TransformerBlock\n",
        "\n",
        "Step 2: Use a placeholder for LayerNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPcyWGCiIZQz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# ===============================\n",
        "# DummyGPTModel — A minimal GPT-like model structure\n",
        "# ===============================\n",
        "class DummyGPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        \"\"\"\n",
        "        Initialize the DummyGPTModel using the given configuration dictionary.\n",
        "\n",
        "        Args:\n",
        "            cfg (dict): A configuration dictionary containing model hyperparameters:\n",
        "                - \"vocab_size\": Size of the token vocabulary.\n",
        "                - \"emb_dim\": Dimensionality of token and positional embeddings.\n",
        "                - \"context_length\": Maximum sequence length (number of positions).\n",
        "                - \"drop_rate\": Dropout probability for embeddings.\n",
        "                - \"n_layers\": Number of Transformer blocks.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding layer for tokens (converts token IDs into embedding vectors)\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "\n",
        "        # Embedding layer for positional encodings (represents token position in sequence)\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "\n",
        "        # Dropout layer applied after combining token and positional embeddings\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        # A stack of \"Transformer blocks\" — here they are dummy placeholders\n",
        "        # Each block would normally contain self-attention + feedforward layers.\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "        )\n",
        "\n",
        "        # A final normalization layer (placeholder)\n",
        "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
        "\n",
        "        # Output layer that maps from embedding dimension to vocabulary size\n",
        "        # Used to generate logits for each token in the vocabulary.\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        \"\"\"\n",
        "        Forward pass of the DummyGPTModel.\n",
        "\n",
        "        Args:\n",
        "            in_idx (torch.Tensor): Tensor of token indices with shape (batch_size, seq_len)\n",
        "\n",
        "        Returns:\n",
        "            logits (torch.Tensor): Output predictions (unnormalized probabilities)\n",
        "                                   of shape (batch_size, seq_len, vocab_size)\n",
        "        \"\"\"\n",
        "        # Extract batch size and sequence length from input\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "\n",
        "        # Token embeddings: Convert token IDs to embedding vectors\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "\n",
        "        # Positional embeddings: Create embeddings for each position in the sequence\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "\n",
        "        # Combine token embeddings with positional embeddings (broadcasting adds position info)\n",
        "        x = tok_embeds + pos_embeds\n",
        "\n",
        "        # Apply dropout regularization\n",
        "        x = self.drop_emb(x)\n",
        "\n",
        "        # Pass through a series of Transformer blocks (here, they do nothing)\n",
        "        x = self.trf_blocks(x)\n",
        "\n",
        "        # Apply final normalization (dummy layer)\n",
        "        x = self.final_norm(x)\n",
        "\n",
        "        # Compute output logits for each token position\n",
        "        logits = self.out_head(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# DummyTransformerBlock — Placeholder for a real Transformer block\n",
        "# ===============================\n",
        "class DummyTransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        \"\"\"\n",
        "        Placeholder Transformer block.\n",
        "        In a real model, this would include:\n",
        "            - Multi-head self-attention\n",
        "            - Feed-forward neural network\n",
        "            - Layer normalization\n",
        "            - Residual connections\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # No real operations here — just a placeholder for architecture structure\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the dummy Transformer block.\n",
        "        Simply returns the input tensor unchanged.\n",
        "        \"\"\"\n",
        "        return x\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# DummyLayerNorm — Placeholder for Layer Normalization\n",
        "# ===============================\n",
        "class DummyLayerNorm(nn.Module):\n",
        "    def __init__(self, normalized_shape, eps=1e-5):\n",
        "        \"\"\"\n",
        "        Dummy LayerNorm initialization.\n",
        "        In a real implementation, this would compute normalization over features.\n",
        "\n",
        "        Args:\n",
        "            normalized_shape (int): Number of features in the input tensor to normalize.\n",
        "            eps (float): Small constant added to denominator for numerical stability.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Placeholder — does not actually normalize the input\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the dummy normalization layer.\n",
        "        Simply returns the input tensor unchanged.\n",
        "        \"\"\"\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGGOyl0OIZQz"
      },
      "source": [
        "The DummyGPTModel class in this code defines a simplified version of a GPT-like model using\n",
        "PyTorch's neural network module (nn.Module).\n",
        "\n",
        "The model architecture in the\n",
        "DummyGPTModel class consists of token and positional embeddings, dropout, a series of\n",
        "transformer blocks (DummyTransformerBlock), a final layer normalization\n",
        "(DummyLayerNorm), and a linear output layer (out_head).\n",
        "\n",
        "The configuration is passed in via\n",
        "a Python dictionary, for instance, the GPT_CONFIG_124M dictionary we created earlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcI1Gz6CIZQz"
      },
      "source": [
        "The forward method describes the data flow through the model: it computes token and\n",
        "positional embeddings for the input indices, applies dropout, processes the data through\n",
        "the transformer blocks, applies normalization, and finally produces logits with the linear\n",
        "output layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae5sjdGiIZQ0"
      },
      "source": [
        "The code above is already functional, as we will see later in this section after we prepare\n",
        "the input data.\n",
        "\n",
        "However, for now, note in the code above that we have used placeholders\n",
        "(DummyLayerNorm and DummyTransformerBlock) for the transformer block and layer\n",
        "normalization, which we will develop in later sections\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orYtGvkOIZQ0"
      },
      "source": [
        "Next, we will prepare the input data and initialize a new GPT model to illustrate its\n",
        "usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws4opT1mIZQ0"
      },
      "source": [
        "### **STEP 1: TOKENIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXmvM-DqIZQ0",
        "outputId": "88a5ec68-788b-463f-b129-164d81349d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "batch = []\n",
        "txt1 = \"Every effort moves you\"\n",
        "txt2 = \"Every day holds a\"\n",
        "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
        "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
        "batch = torch.stack(batch, dim=0)\n",
        "print(batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LksOfLNjIZQ1"
      },
      "source": [
        "### **STEP 2: CREATE AN INSTANCE OF DUMMYGPTMODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXuklEoOIZQ1",
        "outputId": "a105ed5e-ddcc-4428-aff0-f49d0743c826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
            "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
            "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
            "         [ 0.0139,  1.6755, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
            "\n",
            "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
            "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
            "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
            "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = DummyGPTModel(GPT_CONFIG_124M)\n",
        "logits = model(batch)\n",
        "print(\"Output shape:\", logits.shape)\n",
        "print(logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcNeNP8UIZQ1"
      },
      "source": [
        "The output tensor has two rows corresponding to the two text samples. Each text sample\n",
        "consists of 4 tokens; each token is a 50,257-dimensional vector, which matches the size of\n",
        "the tokenizer's vocabulary.\n",
        "\n",
        "\n",
        "The embedding has 50,257 dimensions because each of these dimensions refers to a\n",
        "unique token in the vocabulary. At the end of this chapter, when we implement the\n",
        "postprocessing code, we will convert these 50,257-dimensional vectors back into token IDs,\n",
        "which we can then decode into words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGshYi_9IZQ1"
      },
      "source": [
        "Now that we have taken a top-down look at the GPT architecture and its in- and outputs,\n",
        "we will code the individual placeholders in the upcoming sections, starting with the real\n",
        "layer normalization class that will replace the DummyLayerNorm in the previous code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoPQEqUGIZQ1"
      },
      "source": [
        "## **GPT ARCHITECTURE PART 2: LAYER NORMALIZATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De8dzXqdIZQ1"
      },
      "source": [
        "#### **Explanation with a simple example**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fOnx3R0IZQ1",
        "outputId": "97d64e52-6397-40fe-d927-e50b4389e4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
            "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "batch_example = torch.randn(2, 5) #A\n",
        "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
        "out = layer(batch_example)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsWUZHdGIZQ2"
      },
      "source": [
        "The neural network layer we have coded consists of a Linear layer followed by a non-linear\n",
        "activation function, ReLU (short for Rectified Linear Unit), which is a standard activation\n",
        "function in neural networks.\n",
        "\n",
        "If you are unfamiliar with ReLU, it simply thresholds negative\n",
        "inputs to 0, ensuring that a layer outputs only positive values, which explains why the\n",
        "resulting layer output does not contain any negative values.\n",
        "\n",
        "(Note that we will use another,\n",
        "more sophisticated activation function in GPT, which we will introduce in the next section).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfr-cBxCIZQ2"
      },
      "source": [
        "Before we apply layer normalization to these outputs, let's examine the mean and\n",
        "variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hobvLu9IIZQ2",
        "outputId": "bc172727-3571-44d2-826c-5d0f01a74e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[0.1324],\n",
            "        [0.2170]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[0.0231],\n",
            "        [0.0398]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ],
      "source": [
        "mean = out.mean(dim=-1, keepdim=True)\n",
        "var = out.var(dim=-1, keepdim=True)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBKYnrUIIZQ2"
      },
      "source": [
        "The first row in the mean tensor above contains the mean value for the first input row, and\n",
        "the second output row contains the mean for the second input row."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQSv91k5IZQ2"
      },
      "source": [
        "Using keepdim=True in operations like mean or variance calculation ensures that the\n",
        "output tensor retains the same number of dimensions as the input tensor, even though the\n",
        "operation reduces the tensor along the dimension specified via dim.\n",
        "\n",
        "For instance, without\n",
        "keepdim=True, the returned mean tensor would be a 2-dimensional vector [0.1324,\n",
        "0.2170] instead of a 2×1-dimensional matrix [[0.1324], [0.2170]].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9wBM53yIZQ2"
      },
      "source": [
        "For a 2D tensor (like a matrix), using dim=-1 for operations such as\n",
        "mean or variance calculation is the same as using dim=1.\n",
        "\n",
        "This is because -1 refers to the\n",
        "tensor's last dimension, which corresponds to the columns in a 2D tensor.\n",
        "\n",
        "Later, when\n",
        "adding layer normalization to the GPT model, which produces 3D tensors with shape\n",
        "[batch_size, num_tokens, embedding_size], we can still use dim=-1 for normalization\n",
        "across the last dimension, avoiding a change from dim=1 to dim=2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqpV__2JIZQ2"
      },
      "source": [
        "Next, let us apply layer normalization to the layer outputs we obtained earlier. The\n",
        "operation consists of subtracting the mean and dividing by the square root of the variance\n",
        "(also known as standard deviation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWYT4TlWIZQ2",
        "outputId": "769a15e1-d460-46a7-9ca4-cd4f6eb60aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized layer outputs:\n",
            " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
            "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Mean:\n",
            " tensor([[    0.0000],\n",
            "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ],
      "source": [
        "out_norm = (out - mean) / torch.sqrt(var)\n",
        "mean = out_norm.mean(dim=-1, keepdim=True)\n",
        "var = out_norm.var(dim=-1, keepdim=True)\n",
        "print(\"Normalized layer outputs:\\n\", out_norm)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSJowsBDIZQ2"
      },
      "source": [
        "Note that the value 2.9802e-08 in the output tensor is the scientific notation for 2.9802 ×\n",
        "10-8, which is 0.0000000298 in decimal form. This value is very close to 0, but it is not\n",
        "exactly 0 due to small numerical errors that can accumulate because of the finite precision\n",
        "with which computers represent numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bJuRgg9IZQ2"
      },
      "source": [
        "To improve readability, we can also turn off the scientific notation when printing tensor\n",
        "values by setting sci_mode to False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub-iTTllIZQ2",
        "outputId": "f72cd4e1-0eee-4231-bda9-2e414ce9f9fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[    0.0000],\n",
            "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.set_printoptions(sci_mode=False)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL5y4NNMIZQ2"
      },
      "source": [
        "Let's now encapsulate this process in a PyTorch module that we can use in the GPT\n",
        "model later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGcGuVPbIZQ2"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDJa-t_7IZQ3"
      },
      "source": [
        "This specific implementation of layer Normalization operates on the last dimension of the\n",
        "input tensor x, which represents the embedding dimension (emb_dim).\n",
        "\n",
        "The variable eps is a\n",
        "small constant (epsilon) added to the variance to prevent division by zero during\n",
        "normalization.\n",
        "\n",
        "The scale and shift are two trainable parameters (of the same dimension\n",
        "as the input) that the LLM automatically adjusts during training if it is determined that\n",
        "doing so would improve the model's performance on its training task.\n",
        "\n",
        "This allows the model\n",
        "to learn appropriate scaling and shifting that best suit the data it is processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmCLUM80IZQ3"
      },
      "source": [
        "### **A small note on biased variance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne7NQbfpIZQ3"
      },
      "source": [
        "In our variance calculation method, we have opted for an implementation detail by\n",
        "setting unbiased=False.\n",
        "\n",
        "For those curious about what this means, in the variance\n",
        "calculation, we divide by the number of inputs n in the variance formula.\n",
        "\n",
        "This approach does not apply Bessel's correction, which typically uses n-1 instead of n in\n",
        "the denominator to adjust for bias in sample variance estimation.\n",
        "\n",
        "This decision results in a so-called biased estimate of the variance.\n",
        "\n",
        "For large-scale language\n",
        "models (LLMs), where the embedding dimension n is significantly large, the\n",
        "difference between using n and n-1 is practically negligible.\n",
        "\n",
        "We chose this approach to ensure compatibility with the GPT-2 model's normalization layers and because it\n",
        "reflects TensorFlow's default behavior, which was used to implement the original GPT2 model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJTSy9fRIZQ3"
      },
      "source": [
        "Let's now try the LayerNorm module in practice and apply it to the batch input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KVwBN8fIZQ3",
        "outputId": "c75f9cec-1689-40dc-cf4e-e1f7269537f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[    -0.0000],\n",
            "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ],
      "source": [
        "ln = LayerNorm(emb_dim=5)\n",
        "out_ln = ln(batch_example)\n",
        "mean = out_ln.mean(dim=-1, keepdim=True)\n",
        "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-dH-lujIZQ3"
      },
      "source": [
        "As we can see based on the results, the layer normalization code works as expected and\n",
        "normalizes the values of each of the two inputs such that they have a mean of 0 and a\n",
        "variance of 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtKNdITSLjIx"
      },
      "source": [
        "### **Why Normalization does not do negative effect?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqt5VsXEL26K"
      },
      "source": [
        "The Core Question\n",
        "\n",
        "> “Layer normalization changes the output values numerically, and two same vectors can have different values after normalization at different times.\n",
        "> Why doesn’t this negatively affect training globally?”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZb44CmNLhoz"
      },
      "source": [
        "**What really happens when we normalize**\n",
        "\n",
        "When you apply Layer Normalization, you compute\n",
        "$$\\text{LN}(x) = \\gamma \\cdot \\frac{x - \\mu}{\\sigma + \\epsilon} + \\beta$$\n",
        "\n",
        "* Here, $ \\mu $ and $ \\sigma $ are computed for each input sample separately.\n",
        "* So yes — even if the same input vector appears at different training steps,\n",
        "  its surrounding network context (weights before it, gradients, etc.) may have changed\n",
        "   → which means $ x $, $\\mu $, and $ \\sigma $ will differ slightly.\n",
        "\n",
        "Hence, the *numerical values* after normalization can differ over time.\n",
        "\n",
        "But that’s *not a bug* — it’s part of what helps the model train.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q0EOsq9Msv7"
      },
      "source": [
        "**Why that’s not harmful (and actually helpful)**\n",
        "\n",
        "Even though normalization changes numbers dynamically, training doesn’t get confused because\n",
        "\n",
        "1. The model learns to adapt to normalization\n",
        "\n",
        "> - LayerNorm has trainable parameters γ (scale) and β (bias).They let the network re-scale and re-shift normalized values as needed.\n",
        "> - So if the network needs certain magnitude or offset to represent information,γ and β will learn to bring that back.\n",
        "> - Normalization doesn’t destroy information — it just stabilizes it, then allows the network to “recover” whatever scale/offset it wants.\n",
        "\n",
        "2. Normalization keeps the \"direction\" of information consistent\n",
        "\n",
        "> - When you normalize, you change the magnitude of the activations but keep their relative direction in feature space.\n",
        "> - In deep learning, the relative direction (how features vary together) is what carries information, not the absolute scale.\n",
        "> - So even if the numeric values change, the pattern of information remains intact — and that’s what the next layer learns from.\n",
        "\n",
        "3. It makes optimization more stable globally\n",
        "\n",
        "> Without normalization, during backpropagation\n",
        "> - Activations can explode or vanish (causing unstable gradients)\n",
        "> - Each layer can shift its output distribution unpredictably (called *internal covariate shift*).\n",
        "> - LayerNorm ensures that every layer sees inputs that are roughly **centered and scaled**, regardless of how other layers change.\n",
        "> - This stability lets optimizers (like Adam) make consistent updates even when earlier weights shift slightly.\n",
        "> - So even though the *numbers* change locally, the overall learning process stays stable globally.\n",
        "\n",
        "4. Global model behavior depends on *relative changes*, not absolute values\n",
        "\n",
        "> - Let’s think in terms of training dynamics\n",
        "> - Suppose at time step T₁, a vector $ x_1 $ → normalized → $ y_1 $\n",
        "> - At time step T₂, same vector (but slightly different due to learned weights) → normalized → $ y_2 $\n",
        "> - Even though $ y_1 \\ne y_2 $, the *entire model* (all layers, parameters, gradients) is changing together in a **coordinated way**.\n",
        "> - Training doesn’t require outputs to be numerically stable — only that the optimization process is *consistent* and *gradient-friendly*.\n",
        "> - The model doesn’t rely on *exact numbers*, but rather on how they change relative to the loss landscape.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRUH9FsMNrTM"
      },
      "source": [
        "**Analogy**\n",
        "\n",
        ">Think of LayerNorm like a **thermostat** in a large system.\n",
        ">\n",
        "> - Even though the exact temperature readings (values) fluctuate,\n",
        "> - The thermostat keeps things in a healthy range — preventing overheat or freeze,\n",
        "> - So the overall system (the model) can keep working efficiently.\n",
        "> - The local variations don’t harm the global function — they help maintain global *stability*.\n",
        "\n",
        "**In short**\n",
        "\n",
        "> LayerNorm changes local values dynamically,\n",
        "> but globally it **preserves representational meaning, stabilizes optimization, and keeps gradients healthy.**\n",
        "> That’s why it *helps* rather than hurts training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3DcbruWODH1"
      },
      "source": [
        "### **Batch Normalization vs Layer Normalization**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iCC21hEN-o2"
      },
      "source": [
        "\n",
        "| Feature                              | **Batch Normalization (BatchNorm)**                                                                | **Layer Normalization (LayerNorm)**                                                             |\n",
        "| ------------------------------------ | -------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- |\n",
        "| **Normalization Scope**              | Across the **batch dimension** (mean and variance are computed for each feature across the batch). | Across the **feature dimension** (mean and variance are computed for each sample individually). |\n",
        "| **Used in**                          | Common in **CNNs** and feedforward networks.                                                       | Common in **Transformers**, **RNNs**, and **language models**.                                  |\n",
        "| **Dependency on Batch Size**         | Depends on batch statistics — smaller batches can make training unstable.                          | Independent of batch size — works well even with batch size = 1.                                |\n",
        "| **When statistics are computed**     | During **training**, uses batch stats; during **inference**, uses running (moving average) stats.  | Uses **current input only**, both during training and inference.                                |\n",
        "| **Computation axis**                 | Normalizes each feature across all samples in the batch.                                           | Normalizes all features within a single sample.                                                 |\n",
        "| **Formula**                          | ( \\hat{x} = \\frac{x - \\mu_{batch}}{\\sigma_{batch} + \\epsilon} )                                    | ( \\hat{x} = \\frac{x - \\mu_{layer}}{\\sigma_{layer} + \\epsilon} )                                 |\n",
        "| **Best suited for**                  | Vision models (CNNs), large batches.                                                               | Sequence models (Transformers, NLP), small batches, or variable-length inputs.                  |\n",
        "| **Typical location in architecture** | After linear/convolutional layers.                                                                 | After linear or attention layers.                                                               |\n",
        "| **Training Stability**               | Can fluctuate with batch composition.                                                              | More stable, since normalization is per sample.                                                 |\n",
        "| **Example Use**                      | ResNet, EfficientNet                                                                               | GPT, BERT, Transformer                                                                          |\n",
        "\n",
        "**Simple Intuition**\n",
        "\n",
        "* **BatchNorm:** “I’ll normalize each feature across the whole mini-batch.”\n",
        "* **LayerNorm:** “I’ll normalize all features within each training example.”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIssd5eBIZQ3"
      },
      "source": [
        "## **GPT ARCHITECTURE PART 3: FEEDFORWARD NEURAL NETWORK WITH GELU ACTIVATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guOOKRHAIZQ3"
      },
      "source": [
        "Let's implement the GELU activation function approximation used by GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MvJ6r5uIZQ3"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ny5w6nsIZQ3"
      },
      "source": [
        "To get an idea of what this GELU function looks like and how it compares to the ReLU\n",
        "function, let's plot these functions side by side"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "Me-CGXrYIZQ3",
        "outputId": "f697e1eb-65bc-476b-a5d0-f17c314adda8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gelu, relu = GELU(), nn.ReLU()\n",
        "\n",
        "# Some sample data\n",
        "x = torch.linspace(-3, 3, 100)\n",
        "y_gelu, y_relu = gelu(x), relu(x)\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
        "    plt.subplot(1, 2, i)\n",
        "    plt.plot(x, y)\n",
        "    plt.title(f\"{label} activation function\")\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(f\"{label}(x)\")\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAlHY7XmIZQ3"
      },
      "source": [
        "As we can see in the resulting plot, ReLU is a piecewise linear function that\n",
        "outputs the input directly if it is positive; otherwise, it outputs zero.\n",
        "\n",
        "GELU is a smooth, nonlinear function that approximates ReLU but with a non-zero gradient for negative values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXaciaH_IZQ3"
      },
      "source": [
        "The smoothness of GELU, as shown in the above figure, can lead to better optimization properties\n",
        "during training, as it allows for more nuanced adjustments to the model's parameters.\n",
        "\n",
        "In contrast, ReLU has a sharp corner at zero, which can sometimes make optimization harder,\n",
        "especially in networks that are very deep or have complex architectures.\n",
        "\n",
        "Moreover, unlike RELU, which outputs zero for any negative input, GELU allows for a small, non-zero output\n",
        "for negative values.\n",
        "\n",
        "This characteristic means that during the training process, neurons that\n",
        "receive negative input can still contribute to the learning process, albeit to a lesser extent\n",
        "than positive inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw_gUYqQIZQ3"
      },
      "source": [
        "Next, let's use the GELU function to implement the small neural network module,\n",
        "FeedForward, that we will be using in the LLM's transformer block later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Sk8rENuIZQ4"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-sztEOnIZQ4",
        "outputId": "b13347f0-c306-421f-8f0c-c3ca07831b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768\n"
          ]
        }
      ],
      "source": [
        "print(GPT_CONFIG_124M[\"emb_dim\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCdephV1IZQ4"
      },
      "source": [
        "As we can see in the preceding code, the FeedForward module is a small neural network\n",
        "consisting of two Linear layers and a GELU activation function.\n",
        "\n",
        "In the 124 million parameter GPT model, it receives the input batches with tokens that have an embedding\n",
        "size of 768 each via the GPT_CONFIG_124M dictionary where GPT_CONFIG_124M[\"emb_dim\"]\n",
        "= 768.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdP5JzxOIZQ4"
      },
      "source": [
        "Let's use the GELU function to implement the small neural network module,\n",
        "FeedForward, that we will be using in the LLM's transformer block later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQZ0Ez4PIZQ4",
        "outputId": "e6b2225e-b22b-40f1-fe0c-f0687e295d4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 768])\n"
          ]
        }
      ],
      "source": [
        "ffn = FeedForward(GPT_CONFIG_124M)\n",
        "x = torch.rand(2, 3, 768) #A\n",
        "out = ffn(x)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04dADeiGIZQ4"
      },
      "source": [
        "The FeedForward module we implemented in this section plays a crucial role in enhancing\n",
        "the model's ability to learn from and generalize the data.\n",
        "\n",
        "\n",
        "Although the input and output dimensions of this module are the same, it internally expands the embedding dimension\n",
        "into a higher-dimensional space through the first linear layer.\n",
        "\n",
        "This expansion is followed by a non-linear GELU activation, and then a contraction back to\n",
        "the original dimension with the second linear transformation.\n",
        "\n",
        "Such a design allows for the\n",
        "exploration of a richer representation space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm1GFrIwIZQ4"
      },
      "source": [
        "Moreover, the uniformity in input and output dimensions simplifies the architecture by\n",
        "enabling the stacking of multiple layers, as we will do later, without the need to adjust\n",
        "dimensions between them, thus making the model more scalable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu7_w077IZQ4"
      },
      "source": [
        "## **GPT ARCHITECTURE PART 4: SHORTCUT CONNECTIONS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0197fgdIZQ4"
      },
      "source": [
        "Let us see how we can add shortcut connections to the forward method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqld4dO9IZQ4"
      },
      "outputs": [],
      "source": [
        "class ExampleDeepNeuralNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes, use_shortcut):\n",
        "        super().__init__()\n",
        "        self.use_shortcut = use_shortcut\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            # Compute the output of the current layer\n",
        "            layer_output = layer(x)\n",
        "            # Check if shortcut can be applied\n",
        "            if self.use_shortcut and x.shape == layer_output.shape:\n",
        "                x = x + layer_output\n",
        "            else:\n",
        "                x = layer_output\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkJTfS48IZQ5"
      },
      "source": [
        "The code implements a deep neural network with 5 layers, each consisting of a Linear\n",
        "layer and a GELU activation function.\n",
        "\n",
        "In the forward pass, we iteratively pass the input\n",
        "through the layers and optionally add the shortcut connections  if\n",
        "the self.use_shortcut attribute is set to True."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOEzFML-IZQ5"
      },
      "source": [
        "Let's use this code to first initialize a neural network without shortcut connections. Here,\n",
        "each layer will be initialized such that it accepts an example with 3 input values and returns\n",
        "3 output values. The last layer returns a single output value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTRapbkEIZQ5"
      },
      "outputs": [],
      "source": [
        "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
        "sample_input = torch.tensor([[1., 0., -1.]])\n",
        "torch.manual_seed(123) # specify random seed for the initial weights for reproducibility\n",
        "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
        "layer_sizes, use_shortcut=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMS-7BQQIZQ5"
      },
      "source": [
        "Next, we implement a function that computes the gradients in the the model's backward\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OmWuCcxIZQ5"
      },
      "outputs": [],
      "source": [
        "def print_gradients(model, x):\n",
        "    # Forward pass\n",
        "    output = model(x)\n",
        "    target = torch.tensor([[0.]])\n",
        "\n",
        "    # Calculate loss based on how close the target\n",
        "    # and output are\n",
        "    loss = nn.MSELoss()\n",
        "    loss = loss(output, target)\n",
        "\n",
        "    # Backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            # Print the mean absolute gradient of the weights\n",
        "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bU8pJ-QIZQ5"
      },
      "source": [
        "In the preceding code, we specify a loss function that computes how close the model output\n",
        "and a user-specified target (here, for simplicity, the value 0) are.\n",
        "\n",
        "Then, when calling loss.backward(), PyTorch computes the loss gradient for each layer in the model.\n",
        "\n",
        "We can iterate through the weight parameters via model.named_parameters().\n",
        "\n",
        "Suppose we have a 3×3 weight parameter matrix for a given layer.\n",
        "\n",
        "In that case, this layer will have 3×3 gradient values, and we print the mean absolute gradient of these 3×3 gradient values to\n",
        "obtain a single gradient value per layer to compare the gradients between layers more\n",
        "easily."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAg1qbYvIZQ5"
      },
      "source": [
        "In short, the .backward() method is a convenient method in PyTorch that computes loss\n",
        "gradients, which are required during model training, without implementing the math for the\n",
        "gradient calculation ourselves, thereby making working with deep neural networks much\n",
        "more accessible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pyl0qx9IZQ5"
      },
      "source": [
        "Let's now use the `print_gradients` function and apply it to the model without skip\n",
        "connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOeTs4SdIZQ5",
        "outputId": "fbe5a823-cbde-4fa5-d875-8595e5053fa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight has gradient mean of 0.00020173584925942123\n",
            "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
            "layers.2.0.weight has gradient mean of 0.0007152040489017963\n",
            "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
            "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
          ]
        }
      ],
      "source": [
        "print_gradients(model_without_shortcut, sample_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfVA4kRnIZQ5"
      },
      "source": [
        "As we can see based on the output of the print_gradients function, the gradients become\n",
        "smaller as we progress from the last layer (layers.4) to the first layer (layers.0), which\n",
        "is a phenomenon called the vanishing gradient problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo87eRUyIZQ5"
      },
      "source": [
        "Let's now instantiate a model with skip connections and see how it compares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6s3A9NnIZQ5",
        "outputId": "c64e585b-e2b0-4554-9505-e6d3b1009373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
            "layers.1.0.weight has gradient mean of 0.20694105327129364\n",
            "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
            "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
            "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
        "layer_sizes, use_shortcut=True\n",
        ")\n",
        "print_gradients(model_with_shortcut, sample_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfmoGzwGIZQ5"
      },
      "source": [
        "As we can see, based on the output, the last layer (layers.4) still has a larger gradient\n",
        "than the other layers.\n",
        "\n",
        "However, the gradient value stabilizes as we progress towards the\n",
        "first layer (layers.0) and doesn't shrink to a vanishingly small value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwu1Zy4fIZQ6"
      },
      "source": [
        "In conclusion, shortcut connections are important for overcoming the limitations posed\n",
        "by the vanishing gradient problem in deep neural networks.\n",
        "\n",
        "Shortcut connections are a core building block of very large models such as LLMs, and they will help facilitate more effective\n",
        "training by ensuring consistent gradient flow across layers when we train the GPT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJDdGbv7IZQ6"
      },
      "source": [
        "## **GPT ARCHITECTURE PART 5: CODING ATTENTION AND LINEAR LAYERS IN A TRANSFORMER BLOCK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6juKSJWAIZQ6"
      },
      "source": [
        "Let us code a transformer block as follows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO5VjqP5IZQ6"
      },
      "source": [
        "Step 1: Shortcut connection for attention block\n",
        "\n",
        "Step 2:  Shortcut connection for feed forward block\n",
        "\n",
        "Step 3: Add the original input back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeXZFL3CIZQ9"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        \"\"\"\n",
        "        A single Transformer block that combines:\n",
        "        1. Multi-Head Self-Attention\n",
        "        2. Feed-Forward Network\n",
        "        3. Layer Normalization\n",
        "        4. Residual (skip) connections\n",
        "        5. Dropout regularization\n",
        "\n",
        "        Args:\n",
        "            cfg (dict): Configuration dictionary containing:\n",
        "                - emb_dim: Embedding dimension (input/output feature size)\n",
        "                - context_length: Maximum number of tokens (sequence length)\n",
        "                - n_heads: Number of attention heads\n",
        "                - drop_rate: Dropout rate\n",
        "                - qkv_bias: Whether to use bias in query/key/value projections\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Multi-Head Self-Attention layer\n",
        "        # This lets each token \"attend\" to (look at) other tokens in the sequence\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],            # Input embedding dimension\n",
        "            d_out=cfg[\"emb_dim\"],           # Output dimension (same as input)\n",
        "            context_length=cfg[\"context_length\"],  # Sequence length (number of tokens)\n",
        "            num_heads=cfg[\"n_heads\"],       # Number of parallel attention heads\n",
        "            dropout=cfg[\"drop_rate\"],       # Dropout applied inside attention\n",
        "            qkv_bias=cfg[\"qkv_bias\"]        # Whether to use bias terms in Q, K, V projections\n",
        "        )\n",
        "\n",
        "        # Feed-forward sublayer (position-wise fully connected network)\n",
        "        # Usually consists of two linear layers with a GELU/ReLU activation\n",
        "        self.ff = FeedForward(cfg)\n",
        "\n",
        "        # First Layer Normalization (applied before attention)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "\n",
        "        # Second Layer Normalization (applied before feed-forward)\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "\n",
        "        # Dropout applied to residual (shortcut) connections to prevent overfitting\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the Transformer block.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape [batch_size, num_tokens, emb_dim]\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of the same shape as input\n",
        "        \"\"\"\n",
        "\n",
        "        # ==============================\n",
        "        # 1️⃣ Attention Sub-Layer\n",
        "        # ==============================\n",
        "\n",
        "        # Save input as shortcut (for residual connection)\n",
        "        shortcut = x\n",
        "\n",
        "        # Apply layer normalization before attention\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # Apply multi-head self-attention\n",
        "        # Each token attends to other tokens and aggregates contextual info\n",
        "        x = self.att(x)  # Shape: [batch_size, num_tokens, emb_dim]\n",
        "\n",
        "        # Apply dropout to attention output for regularization\n",
        "        x = self.drop_shortcut(x)\n",
        "\n",
        "        # Add the original input (residual connection)\n",
        "        # Helps prevent vanishing gradients and preserves original information\n",
        "        x = x + shortcut\n",
        "\n",
        "        # ==============================\n",
        "        # 2️⃣ Feed-Forward Sub-Layer\n",
        "        # ==============================\n",
        "\n",
        "        # Save input again for another residual connection\n",
        "        shortcut = x\n",
        "\n",
        "        # Apply layer normalization before feed-forward network\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        # Pass through the feed-forward network\n",
        "        x = self.ff(x)\n",
        "\n",
        "        # Apply dropout to feed-forward output\n",
        "        x = self.drop_shortcut(x)\n",
        "\n",
        "        # Add the shortcut again (residual connection)\n",
        "        x = x + shortcut\n",
        "\n",
        "        # ==============================\n",
        "        # 3️⃣ Output\n",
        "        # ==============================\n",
        "\n",
        "        # Return the transformed tensor (same shape as input)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWIbWqmHIZQ9"
      },
      "source": [
        "The given code defines a TransformerBlock class in PyTorch that includes a multi-head\n",
        "attention mechanism (MultiHeadAttention) and a feed forward network (FeedForward),\n",
        "both configured based on a provided configuration dictionary (cfg), such as\n",
        "GPT_CONFIG_124M"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBfnIZ5hIZQ9"
      },
      "source": [
        "Layer normalization (LayerNorm) is applied before each of these two components, and\n",
        "dropout is applied after them to regularize the model and prevent overfitting.\n",
        "\n",
        "This is also known as Pre-LayerNorm.\n",
        "\n",
        "Older architectures, such as the original transformer model,\n",
        "applied layer normalization after the self-attention and feed-forward networks instead,\n",
        "known as Post-LayerNorm, which often leads to worse training dynamics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqC2uxczIZQ9"
      },
      "source": [
        "The class also implements the forward pass, where each component is followed by a\n",
        "shortcut connection that adds the input of the block to its output. This critical feature helps\n",
        "gradients flow through the network during training and improves the learning of deep\n",
        "models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaftcnuwIZQ9"
      },
      "source": [
        "Using the GPT_CONFIG_124M dictionary we defined earlier, let's instantiate a transformer\n",
        "block and feed it some sample data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qA6jRILIZQ9"
      },
      "source": [
        "Create sample input of shape [batch_size, num_tokens, emb_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dDEfFX6IZQ-",
        "outputId": "8679a5e0-549e-48e9-aa44-2112ffc9c570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "x = torch.rand(2, 4, 768) #A\n",
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "output = block(x)\n",
        "print(\"Input shape:\", x.shape)\n",
        "print(\"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99e3cOGUIZQ-"
      },
      "source": [
        "As we can see from the code output, the transformer block maintains the input dimensions\n",
        "in its output, indicating that the transformer architecture processes sequences of data\n",
        "without altering their shape throughout the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpcG_iMeIZQ-"
      },
      "source": [
        "  \n",
        "The preservation of shape throughout the transformer block architecture is not incidental\n",
        "but a crucial aspect of its design.\n",
        "\n",
        "This design enables its effective application across a wide\n",
        "range of sequence-to-sequence tasks, where each output vector directly corresponds to an\n",
        "input vector, maintaining a one-to-one relationship."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2waF1KGIZQ-"
      },
      "source": [
        "However, the output is a context vector\n",
        "that encapsulates information from the entire input sequence.\n",
        "\n",
        "This means that while the physical dimensions of the sequence (length and feature size)\n",
        "remain unchanged as it passes through the transformer block, the content of each output\n",
        "vector is re-encoded to integrate contextual information from across the entire input\n",
        "sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvctwN7NIZQ-"
      },
      "source": [
        "## **GPT ARCHITECTURE PART 6: ENTIRE GPT MODEL ARCHITECTURE IMPLEMENTATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5ayGy00IZQ-"
      },
      "source": [
        "The device setting will allow us to train the model on a CPU or GPU, depending on which device the input\n",
        "data sits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMdf4fJCIZQ_"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        \"\"\"\n",
        "        GPTModel — A simplified Generative Pretrained Transformer (GPT)-style model.\n",
        "\n",
        "        This model processes sequences of token IDs and predicts the next token\n",
        "        in a sequence using a stack of Transformer blocks.\n",
        "\n",
        "        Args:\n",
        "            cfg (dict): Configuration dictionary containing:\n",
        "                - vocab_size: Total number of unique tokens (vocabulary size)\n",
        "                - emb_dim: Embedding dimension (size of each token vector)\n",
        "                - context_length: Maximum number of tokens in one input sequence\n",
        "                - drop_rate: Dropout probability (for regularization)\n",
        "                - n_layers: Number of stacked Transformer blocks\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # ===============================\n",
        "        # 1️⃣ Embedding Layers\n",
        "        # ===============================\n",
        "\n",
        "        # Token embedding: Converts token indices into continuous embedding vectors\n",
        "        # Shape after embedding → [batch_size, seq_len, emb_dim]\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "\n",
        "        # Positional embedding: Adds information about token positions in the sequence\n",
        "        # Each position (0, 1, 2, … context_length-1) has its own embedding vector\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "\n",
        "        # Dropout layer for regularization applied to embeddings\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        # ===============================\n",
        "        # 2️⃣ Transformer Blocks\n",
        "        # ===============================\n",
        "\n",
        "        # Stack of multiple Transformer blocks (each block = attention + feedforward)\n",
        "        # The '*' operator unpacks the list of blocks inside nn.Sequential\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "        )\n",
        "\n",
        "        # ===============================\n",
        "        # 3️⃣ Final Layers\n",
        "        # ===============================\n",
        "\n",
        "        # Layer normalization applied after all transformer layers\n",
        "        # This helps stabilize the output representations\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "\n",
        "        # Linear layer (output head): Maps each token’s embedding\n",
        "        # to a vector of size 'vocab_size' — i.e., prediction logits for each token\n",
        "        # No bias term because embedding and output projections often share weights\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        \"\"\"\n",
        "        Forward pass through the GPT model.\n",
        "\n",
        "        Args:\n",
        "            in_idx (torch.Tensor): Input tensor of token indices,\n",
        "                                   shape [batch_size, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            logits (torch.Tensor): Predicted unnormalized probabilities for each token,\n",
        "                                   shape [batch_size, seq_len, vocab_size]\n",
        "        \"\"\"\n",
        "        # Extract batch size and sequence length from the input tensor\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "\n",
        "        # ===============================\n",
        "        # 1️⃣ Token + Positional Embeddings\n",
        "        # ===============================\n",
        "\n",
        "        # Get token embeddings for each input token ID\n",
        "        tok_embeds = self.tok_emb(in_idx)  # Shape: [batch_size, seq_len, emb_dim]\n",
        "\n",
        "        # Create position indices (0 to seq_len-1) and get their embeddings\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "\n",
        "        # Combine token embeddings with position embeddings\n",
        "        # Adds positional information to each token representation\n",
        "        x = tok_embeds + pos_embeds  # Shape: [batch_size, seq_len, emb_dim]\n",
        "\n",
        "        # Apply dropout to prevent overfitting\n",
        "        x = self.drop_emb(x)\n",
        "\n",
        "        # ===============================\n",
        "        # 2️⃣ Transformer Encoder Blocks\n",
        "        # ===============================\n",
        "\n",
        "        # Pass embeddings through the stack of Transformer blocks\n",
        "        # Each block performs self-attention + feed-forward processing\n",
        "        x = self.trf_blocks(x)\n",
        "\n",
        "        # Apply final layer normalization\n",
        "        x = self.final_norm(x)\n",
        "\n",
        "        # ===============================\n",
        "        # 3️⃣ Output Projection\n",
        "        # ===============================\n",
        "\n",
        "        # Project each embedding vector to vocabulary logits\n",
        "        # This produces predictions for the next token at each position\n",
        "        logits = self.out_head(x)  # Shape: [batch_size, seq_len, vocab_size]\n",
        "\n",
        "        # Return logits (to be used with cross-entropy loss during training)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r0Ae5_aIZQ_"
      },
      "source": [
        "  \n",
        "The `__init__` constructor of this GPTModel class initializes the token and positional\n",
        "embedding layers using the configurations passed in via a Python dictionary, cfg.\n",
        "\n",
        "These\n",
        "embedding layers are responsible for converting input token indices into dense vectors and\n",
        "adding positional information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiLgb6hnIZQ_"
      },
      "source": [
        "   \n",
        "Next, the `__init__` method creates a sequential stack of TransformerBlock modules\n",
        "equal to the number of layers specified in cfg.\n",
        "\n",
        "Following the transformer blocks, a\n",
        "LayerNorm layer is applied, standardizing the outputs from the transformer blocks to\n",
        "stabilize the learning process.\n",
        "\n",
        "Finally, a linear output head without bias is defined, which\n",
        "projects the transformer's output into the vocabulary space of the tokenizer to generate\n",
        "logits for each token in the vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miHymGhjIZQ_"
      },
      "source": [
        "   \n",
        "The forward method takes a batch of input token indices, computes their embeddings,\n",
        "applies the positional embeddings, passes the sequence through the transformer blocks,\n",
        "normalizes the final output, and then computes the logits, representing the next token's\n",
        "unnormalized probabilities. We will convert these logits into tokens and text outputs in the\n",
        "next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZCFEw4kIZQ_"
      },
      "source": [
        "Let's now initialize the 124 million parameter GPT model using the GPT_CONFIG_124M\n",
        "dictionary we pass into the cfg parameter and feed it with the batch text input we created\n",
        "at the beginning of this chapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dDHLqulIZQ_",
        "outputId": "f6cad7a8-e858-4ba8-aae1-5c69b698fdf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch:\n",
            " tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n",
            "\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
            "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
            "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
            "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
            "\n",
            "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
            "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
            "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
            "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "out = model(batch)\n",
        "print(\"Input batch:\\n\", batch)\n",
        "print(\"\\nOutput shape:\", out.shape)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHCtJMMCIZQ_"
      },
      "source": [
        "As we can see, the output tensor has the shape [2, 4, 50257], since we passed in 2 input\n",
        "texts with 4 tokens each. The last dimension, 50,257, corresponds to the vocabulary size of\n",
        "the tokenizer. In the next section, we will see how to convert each of these 50,257-\n",
        "dimensional output vectors back into tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2NBUG3VIZRA"
      },
      "source": [
        "Using the numel() method, short for \"number of elements,\" we can collect the total\n",
        "number of parameters in the model's parameter tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg9W8MnyIZRA",
        "outputId": "e3cd24dd-b6f0-412f-9e91-280e02ee6cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 163,009,536\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u_3yt-FIZRA"
      },
      "source": [
        "Earlier, we spoke of initializing a 124\n",
        "million parameter GPT model, so why is the actual number of parameters 163 million, as\n",
        "shown in the preceding code output?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwtwfyFHIZRA"
      },
      "source": [
        "The reason is a concept called weight tying that is used in the original GPT-2\n",
        "architecture, which means that the original GPT-2 architecture is reusing the weights from\n",
        "the token embedding layer in its output layer.\n",
        "\n",
        "To understand what this means, let's take a\n",
        "look at the shapes of the token embedding layer and linear output layer that we initialized\n",
        "on the model via the GPTModel earlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZDNa9uTIZRA",
        "outputId": "109d1c1e-f33e-4d1e-e76a-a4879fdb79f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token embedding layer shape: torch.Size([50257, 768])\n",
            "Output layer shape: torch.Size([50257, 768])\n"
          ]
        }
      ],
      "source": [
        "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
        "print(\"Output layer shape:\", model.out_head.weight.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QHq2_1QIZRA"
      },
      "source": [
        "As we can see based on the print outputs, the weight tensors for both these layers have the\n",
        "same shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2pc7xRQIZRA"
      },
      "source": [
        "The token embedding and output layers are very large due to the number of rows for the\n",
        "50,257 in the tokenizer's vocabulary. Let's remove the output layer parameter count from\n",
        "the total GPT-2 model count according to the weight tying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22gG_maaIZRA",
        "outputId": "17b097e0-e88b-471e-fa21-eead2d525f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters considering weight tying: 124,412,160\n"
          ]
        }
      ],
      "source": [
        "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
        "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKBk8ePFIZRA"
      },
      "source": [
        "As we can see, the model is now only 124 million parameters large, matching the original\n",
        "size of the GPT-2 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyTHuFF1IZRA"
      },
      "source": [
        "   \n",
        "Weight tying reduces the overall memory footprint and computational complexity of the\n",
        "model. However, in my experience, using separate token embedding and output layers\n",
        "results in better training and model performance; hence, we are using separate layers in\n",
        "our GPTModel implementation. The same is true for modern LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYtKH5jbIZRA"
      },
      "source": [
        "Lastly, let us compute the memory requirements of the 163 million parameters in our\n",
        "GPTModel object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W7-_9pMIZRA",
        "outputId": "6add4f50-6ef9-4b98-f24a-94942a9ada97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total size of the model: 621.83 MB\n"
          ]
        }
      ],
      "source": [
        "total_size_bytes = total_params * 4 #A\n",
        "total_size_mb = total_size_bytes / (1024 * 1024) #B\n",
        "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdqhsL04IZRA"
      },
      "source": [
        "   \n",
        "In conclusion, by calculating the memory requirements for the 163 million parameters in\n",
        "our GPTModel object and assuming each parameter is a 32-bit float taking up 4 bytes, we\n",
        "find that the total size of the model amounts to 621.83 MB, illustrating the relatively large\n",
        "storage capacity required to accommodate even relatively small LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcAux7UUIZRB"
      },
      "source": [
        "   \n",
        "In this section, we implemented the GPTModel architecture and saw that it outputs\n",
        "numeric tensors of shape [batch_size, num_tokens, vocab_size]. In the next section,\n",
        "we will write the code to convert these output tensors into text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT5hUxDJIZRB"
      },
      "source": [
        "## **GPT ARCHITECTURE PART 7: GENERATING TEXT FROM OUTPUT TOKENS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p16jW4rCIZRB"
      },
      "source": [
        "Let us implement the token-generation process as follows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYyfVbREIZRB"
      },
      "source": [
        "Step 1: idx is a (batch, n_tokens) array of indices in the current context\n",
        "\n",
        "Step 2: Crop current context if it exceeds the supported context size E.g., if LLM supports only 5 tokens, and the\n",
        "context size is 10 then only the last 5 tokens are used as context\n",
        "\n",
        "Step 3: Focus only on the last time step, so that (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
        "\n",
        "Step 4: probas has shape (batch, vocab_size)\n",
        "\n",
        "Step 5: idx_next has shape (batch, 1)\n",
        "\n",
        "Step 6: Append sampled index to the running sequence, where idx has shape (batch, n_tokens+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvaGC0NKIZRB"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8WpA3eQIZRB"
      },
      "source": [
        "   \n",
        "In the preceeding code, the generate_text_simple function, we use a softmax function to\n",
        "convert the logits into a probability distribution from which we identify the position with the\n",
        "highest value via torch.argmax.\n",
        "\n",
        "The softmax function is monotonic, meaning it preserves\n",
        "the order of its inputs when transformed into outputs.\n",
        "\n",
        "So, in practice, the softmax step is\n",
        "redundant since the position with the highest score in the softmax output tensor is the\n",
        "same position in the logit tensor.\n",
        "\n",
        "In other words, we could apply the torch.argmax function\n",
        "to the logits tensor directly and get identical results.\n",
        "\n",
        "However, we coded the conversion to\n",
        "illustrate the full process of transforming logits to probabilities, which can add additional\n",
        "intuition, such as that the model generates the most likely next token, which is known as\n",
        "greedy decoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6on4cD2IZRB"
      },
      "source": [
        "    \n",
        "In the next chapter, when we will implement the GPT training code, we will also\n",
        "introduce additional sampling techniques where we modify the softmax outputs such that\n",
        "the model doesn't always select the most likely token, which introduces variability and\n",
        "creativity in the generated text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TM6zOZWIZRB"
      },
      "source": [
        "Let's now try out the generate_text_simple function with the \"Hello, I am\" context\n",
        "as model input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRfxKQGPIZRB"
      },
      "source": [
        "First, we encode the input context into token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SbglOTJIZRB",
        "outputId": "d3bcc9bc-7940-4ac6-8455-700ec0873110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "start_context = \"Hello, I am\"\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"encoded:\", encoded)\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii6vWsRWIZRB"
      },
      "source": [
        "Next, we put the model into `.eval()` mode, which disables random components like\n",
        "dropout, which are only used during training, and use the generate_text_simple function\n",
        "on the encoded input tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptMjhOtOIZRB"
      },
      "source": [
        "We disable dropout since we are not training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhGGUifAIZRB",
        "outputId": "7618a365-6a16-4186-bf91-6ab691b644bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
            "Output length: 10\n"
          ]
        }
      ],
      "source": [
        "model.eval() #A\n",
        "out = generate_text_simple(\n",
        "model=model,\n",
        "idx=encoded_tensor,\n",
        "max_new_tokens=6,\n",
        "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output:\", out)\n",
        "print(\"Output length:\", len(out[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXyydYgoIZRB"
      },
      "source": [
        "Using the .decode method of the tokenizer, we can convert the IDs back into text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMust-p1IZRC",
        "outputId": "59a696ad-80c6-441a-8432-1b2c260f6d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am Featureiman Byeswickattribute argue\n"
          ]
        }
      ],
      "source": [
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roeqQTuSIZRC"
      },
      "source": [
        "As we can see, based on the preceding output, the model generated gibberish, which is not\n",
        "at all coherent text.\n",
        "\n",
        "What happened?\n",
        "\n",
        "The reason why the model is unable to produce coherent text is that we haven't trained it yet.\n",
        "\n",
        "So far, we just\n",
        "implemented the GPT architecture and initialized a GPT model instance with initial random\n",
        "weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN4flDE83-YY"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3sVSwybUt5N"
      },
      "source": [
        "# **EVALUATING GENERATIVE TEXT MODELS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4KhIx6zUt5N"
      },
      "source": [
        "### **GPT Model class we coded earlier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjb3oxcwUt5N"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OBlN7noUt5O"
      },
      "source": [
        "### **Using GPT to generate text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdYmXu17Ut5O"
      },
      "source": [
        "We initialize a GPT model using the code from the previous chapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZwRATEdUt5O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval();  # Disable dropout during inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImoU4Hc3Ut5O"
      },
      "source": [
        "We reduce the context length (context_length) of only 256 tokens to reduce the computational resource requirements for training the model, whereas the original 124 million parameter GPT-2 model used 1024 tokens\n",
        "\n",
        "This is so that more readers will be able to follow and execute the code examples on their laptop computer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgKfx9pLUt5O"
      },
      "source": [
        "Next, we use the `generate_text_simple` function from the previous chapter to generate text.\n",
        "\n",
        "In addition, we define two convenience functions, `text_to_token_ids and `token_ids_to_text`, for converting between token and text representations that we use throughout this chapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6BrjgpGUt5O",
        "outputId": "4fe83963-ba85-406d-903a-8ebbca09e297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDOkd_yoUt5O"
      },
      "source": [
        "As we can see above, the model does not produce good text because it has not been trained yet\n",
        "\n",
        "How do we measure or capture what \"good text\" is, in a numeric form, to track it during training?\n",
        "\n",
        "The next subsection introduces metrics to calculate a loss metric for the generated outputs that we can use to measure the training progress\n",
        "\n",
        "The next chapters on finetuning LLMs will also introduce additional ways to measure model quality\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOvqBcrKUt5O"
      },
      "source": [
        "### **Calculating the text generation loss: cross-entropy and perplexity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRhEj2OtUt5O"
      },
      "source": [
        "Suppose we have an inputs tensor containing the token IDs for 2 training examples (rows)\n",
        "\n",
        "Corresponding to the inputs, the targets contain the desired token IDs that we want the model to generate\n",
        "\n",
        "Notice that the targets are the inputs shifted by 1 position, as explained in chapter 2 when we implemented the data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgfA6zRiUt5O"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])   #  \"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
        "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQp_ZYi9Ut5O"
      },
      "source": [
        "Feeding the inputs to the model, we obtain the logits vector for the 2 input examples that consist of 3 tokens each\n",
        "\n",
        "Each of the tokens is a 50,257-dimensional vector corresponding to the size of the vocabulary\n",
        "\n",
        "Applying the softmax function, we can turn the logits tensor into a tensor of the same dimension containing probability scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpfiEadjUt5O",
        "outputId": "57b26664-8426-4428-92eb-01c99ce6c619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    logits = model(inputs)\n",
        "\n",
        "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
        "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYw9FuopUt5O"
      },
      "source": [
        "As discussed in the previous chapter, we can apply the argmax function to convert the probability scores into predicted token IDs.\n",
        "\n",
        "The softmax function above produced a 50,257-dimensional vector for each token; the argmax function returns the position of the highest probability score in this vector, which is the predicted token ID for the given token.\n",
        "\n",
        "Since we have 2 input batches with 3 tokens each, we obtain 2 by 3 predicted token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc8GO_zcUt5O",
        "outputId": "d672f31d-85c9-458c-bf5a-cb9802229eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[16657],\n",
            "         [  339],\n",
            "         [42826]],\n",
            "\n",
            "        [[49906],\n",
            "         [29669],\n",
            "         [41751]]])\n"
          ]
        }
      ],
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA-P9VAFUt5P"
      },
      "source": [
        "If we decode these tokens, we find that these are quite different from the tokens we want the model to predict, namely the target tokens.\n",
        "\n",
        "That's because the model wasn't trained yet.\n",
        "\n",
        "To train the model, we need to know how far it is away from the correct predictions (targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt5Mf_kvUt5P",
        "outputId": "63191016-9339-4c11-9274-1d091e20c673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1:  Armed heNetflix\n"
          ]
        }
      ],
      "source": [
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQT6CmADUt5P"
      },
      "source": [
        "### **Cross-entropy loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_g2NSCvUt5P"
      },
      "source": [
        "The token probabilities corresponding to the target indices are as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csshdy9yUt5P",
        "outputId": "34d0943f-80ae-4714-e3d6-3fe4d5ec26f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([    0.0001,     0.0000,     0.0000])\n",
            "Text 2: tensor([    0.0000,     0.0001,     0.0000])\n"
          ]
        }
      ],
      "source": [
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz1g-mzWUt5P"
      },
      "source": [
        "We want to maximize all these values, bringing them close to a probability of 1.\n",
        "    \n",
        "In mathematical optimization, it is easier to maximize the logarithm of the probability score than the probability score itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMz_N7T6Ut5P",
        "outputId": "592b5efb-d3f6-497b-e7d3-2314abdf5b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
          ]
        }
      ],
      "source": [
        "# Compute logarithm of all token probabilities\n",
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NcsLWT1Ut5P"
      },
      "source": [
        "Next, we compute the average log probability:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9VO4y-GUt5P",
        "outputId": "688b12de-dc34-4ed9-8e3f-fd83d92f269b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10.7940)\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average probability for each token\n",
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNwxn9CwUt5P"
      },
      "source": [
        "The goal is to make this average log probability as large as possible by optimizing the model weights.\n",
        "\n",
        "Due to the log, the largest possible value is 0, and we are currently far away from 0.\n",
        "\n",
        "In deep learning, instead of maximizing the average log-probability, it's a standard convention to minimize the negative average log-probability value; in our case, instead of maximizing -10.7722 so that it approaches 0, in deep learning, we would minimize 10.7722 so that it approaches 0.\n",
        "\n",
        "The value negative of -10.7722, i.e., 10.7722, is also called cross-entropy loss in deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhtSQ0-1Ut5P",
        "outputId": "8cbbc0d6-b5c4-4d6d-ae4d-21bac65aa2d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7940)\n"
          ]
        }
      ],
      "source": [
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNvlOsegUt5P"
      },
      "source": [
        "PyTorch already implements a cross_entropy function that carries out the previous steps\n",
        "\n",
        "Before we apply the cross_entropy function, let's check the shape of the logits and targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99EW7WKjUt5P",
        "outputId": "9dfcf53c-bb78-4e90-cf19-a4197a39639e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: torch.Size([2, 3, 50257])\n",
            "Targets shape: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
        "print(\"Logits shape:\", logits.shape)\n",
        "\n",
        "# Targets have shape (batch_size, num_tokens)\n",
        "print(\"Targets shape:\", targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6V8w9pQUt5Q"
      },
      "source": [
        "For the cross_entropy function in PyTorch, we want to flatten these tensors by combining them over the batch dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mMGn9IlUt5Q",
        "outputId": "38bb2924-aba0-4e95-cc1d-faefdd712b05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits: torch.Size([6, 50257])\n",
            "Flattened targets: torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "print(\"Flattened targets:\", targets_flat.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoj4QElqUt5Q"
      },
      "source": [
        "Note that the targets are the token IDs, which also represent the index positions in the logits tensors that we want to maximize.\n",
        "    \n",
        "The cross_entropy function in PyTorch will automatically take care of applying the softmax and log-probability computation internally over those token indices in the logits that are to be maximized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8OKdW90Ut5Q",
        "outputId": "59fb6830-2813-4af1-e551-7d829daea0d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7940)\n"
          ]
        }
      ],
      "source": [
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV1raew0Ut5Q"
      },
      "source": [
        "### **Perplexity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPjRZ9FhUt5Q"
      },
      "source": [
        "A concept related to the cross-entropy loss is the perplexity of an LLM.\n",
        "\n",
        "The perplexity is simply the exponential of the cross-entropy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKmJpPAgUt5Q",
        "outputId": "2406f331-8cdd-45b6-88ec-b7d2df55d277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(48725.8203)\n"
          ]
        }
      ],
      "source": [
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no9cKT64Ut5Q"
      },
      "source": [
        "The perplexity is often considered more interpretable because it can be understood as the effective vocabulary size that the model is uncertain about at each step (in the example above, that'd be 48,725 words or tokens).\n",
        "\n",
        "In other words, perplexity provides a measure of how well the probability distribution predicted by the model matches the actual distribution of the words in the dataset.\n",
        "    \n",
        "Similar to the loss, a lower perplexity indicates that the model predictions are closer to the actual distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5nI2eVwUt5Q"
      },
      "source": [
        "### **Calculating the training and validation set losses**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFhedz4OUt5Q"
      },
      "source": [
        "We use a relatively small dataset for training the LLM (in fact, only one short story)\n",
        "\n",
        "The reasons are:\n",
        "\n",
        "You can run the code examples in a few minutes on a laptop computer without a suitable GPU.\n",
        "\n",
        "The training finishes relatively fast (minutes instead of weeks), which is good for educational purposes.\n",
        "    \n",
        "We use a text from the public domain, which can be included in this GitHub repository without violating any usage rights or bloating the repository size.\n",
        "    \n",
        "For example, Llama 2 7B required 184,320 GPU hours on A100 GPUs to be trained on 2 trillion tokens\n",
        "\n",
        "At the time of this writing, the hourly cost of an 8xA100 cloud server at AWS is approximately 30 dollars.\n",
        "\n",
        "So, via an off-the-envelope calculation, training this LLM would cost 184,320 / 8 * 30 = 690,000 dollars\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPARFx5WUt5Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "file_path = \"the-verdict.txt\"\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        text_data = response.read().decode('utf-8')\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text_data)\n",
        "else:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data = file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ81_jxQUt5Q"
      },
      "source": [
        "A quick check that the text loaded ok by printing the first and last 100 words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu8zS1uiUt5Q",
        "outputId": "b9410b9d-71e0-4d8a-acc9-478aa20e33d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I had always thought Jack Gisburn rather a cheap genius--though a\n",
            "\n",
            "good fellow enough--so it was no\n"
          ]
        }
      ],
      "source": [
        "# First 100 characters\n",
        "print(text_data[:99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltcBPjG5Ut5R",
        "outputId": "d23ea444-a9fe-45ef-c695-12670dab920d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "and alone, and happen once--but\n",
            "\n",
            "there's no exterminating our kind of art.\"\n",
            "\n",
            "The End of The Verdict\n"
          ]
        }
      ],
      "source": [
        "# Last 100 characters\n",
        "print(text_data[-99:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXCtbAoYUt5R",
        "outputId": "adc881e9-3c28-42f7-eb0e-ecc64fb8e13c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 20758\n",
            "Tokens: 5765\n"
          ]
        }
      ],
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-h4oAJtUt5R"
      },
      "source": [
        "With 5,145 tokens, the text is very short for training an LLM, but again, it's for educational purposes (we will also load pretrained weights later).\n",
        "\n",
        "Next, we divide the dataset into a training and a validation set and use the data loaders from chapter 2 to prepare the batches for LLM training.\n",
        "    \n",
        "For visualization purposes, the figure below assumes a max_length=6, but for the training loader, we set the max_length equal to the context length that the LLM supports.\n",
        "\n",
        "Since we train the LLM to predict the next word in the text, the targets look the same as these inputs, except that the targets are shifted by one position    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwxa9OYqUt5R"
      },
      "outputs": [],
      "source": [
        "# Train/validation ratio\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X84GkJQdUt5R"
      },
      "outputs": [],
      "source": [
        "# Sanity check\n",
        "\n",
        "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the training loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"increase the `training_ratio`\")\n",
        "\n",
        "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the validation loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"decrease the `training_ratio`\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXW9YdFzUt5R"
      },
      "source": [
        "We use a relatively small batch size to reduce the computational resource demand, and because the dataset is very small to begin with.\n",
        "\n",
        "Llama 2 7B was trained with a batch size of 1024, for example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rITfC8iLUt5R"
      },
      "source": [
        "An optional check that the data was loaded correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqtIdyfmUt5R",
        "outputId": "cc81ed29-5dea-41c1-b0bf-7fffd0e73e2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        "    print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laLsAobXUt5S"
      },
      "source": [
        "An optional check that the data was loaded correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBZE3IvLUt5S",
        "outputId": "016ec202-2462-45d5-c5ad-0fed97afe2b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training tokens: 5120\n",
            "Validation tokens: 512\n",
            "All tokens: 5632\n"
          ]
        }
      ],
      "source": [
        "train_tokens = 0\n",
        "for input_batch, target_batch in train_loader:\n",
        "    train_tokens += input_batch.numel()\n",
        "\n",
        "val_tokens = 0\n",
        "for input_batch, target_batch in val_loader:\n",
        "    val_tokens += input_batch.numel()\n",
        "\n",
        "print(\"Training tokens:\", train_tokens)\n",
        "print(\"Validation tokens:\", val_tokens)\n",
        "print(\"All tokens:\", train_tokens + val_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBE0GESYUt5S"
      },
      "source": [
        "Next, we implement a utility function to calculate the cross-entropy loss of a given batch.\n",
        "\n",
        "In addition, we implement a second utility function to compute the loss for a user-specified number of batches in a data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71gREdTDUt5S"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JaNIPpyUt5S"
      },
      "source": [
        "If you have a machine with a CUDA-supported GPU, the LLM will train on the GPU without making any changes to the code.\n",
        "    \n",
        "Via the device setting, we ensure that the data is loaded onto the same device as the LLM model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZNPFh3lUt5T",
        "outputId": "ae00f623-eb73-4413-8237-53b74ffb2f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.970044708251953\n",
            "Validation loss: 10.984174728393555\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# However, the resulting loss values may be slightly different.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "#\n",
        "# print(f\"Using {device} device.\")\n",
        "\n",
        "\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
        "\n",
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vby0GwcUt5T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ_3fFxnS8Y-"
      },
      "source": [
        "# **TRAINING LOOP FOR THE LLM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw57epoxS8Y_"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW1Gq13nS8Y_"
      },
      "source": [
        "Step 1: Initialize lists to track losses and tokens seen\n",
        "\n",
        "Step 2: Start the main training loop\n",
        "\n",
        "Step 3: Reset loss gradients from previous batch iteration\n",
        "\n",
        "Step 4: Calculate loss gradients\n",
        "\n",
        "Step 5: Update model weights using loss gradients\n",
        "\n",
        "Step 6: Optional evaluation step\n",
        "\n",
        "Step 7: Print a sample text after each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a06OpGCIS8Y_"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61gfXKMDS8Y_"
      },
      "source": [
        "The evaluate_model function calculates the loss over the training and\n",
        "validation set while ensuring the model is in evaluation mode with gradient tracking and\n",
        "dropout disabled when calculating the loss over the training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCDzR209S8Y_"
      },
      "outputs": [],
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8jVbmriS8Y_"
      },
      "source": [
        "The generate_and_print_sample function is a convenience function that we use to track whether the model improves during the training.\n",
        "\n",
        "In particular, the generate_and_print_sample function takes a text snippet (start_context) as input,\n",
        "converts it into token IDs, and feeds it to the LLM to generate a text sample using the\n",
        "generate_text_simple function we used earlier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "japAGWE8S8Y_"
      },
      "source": [
        "Let's see this all in action by training a GPTModel instance for 10 epochs using an AdamW\n",
        "optimizer and the train_model_simple function we defined earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sABTOrVS8Y_",
        "outputId": "0cbd7eae-6da4-472f-dfd6-93c65df96a92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.350, Val loss 9.452\n",
            "Ep 1 (Step 000005): Train loss 7.784, Val loss 7.938\n",
            "Every effort moves you                                                  \n",
            "Ep 2 (Step 000010): Train loss 6.496, Val loss 6.811\n",
            "Ep 2 (Step 000015): Train loss 5.825, Val loss 6.393\n",
            "Every effort moves you, the                                                \n",
            "Ep 3 (Step 000020): Train loss 5.721, Val loss 6.334\n",
            "Ep 3 (Step 000025): Train loss 5.500, Val loss 6.360\n",
            "Every effort moves you, and                                                \n",
            "Ep 4 (Step 000030): Train loss 5.289, Val loss 6.294\n",
            "Ep 4 (Step 000035): Train loss 5.270, Val loss 6.368\n",
            "Every effort moves you                              \", and, and I had been.           \n",
            "Ep 5 (Step 000040): Train loss 5.140, Val loss 6.502\n",
            "Ep 5 (Step 000045): Train loss 5.131, Val loss 6.384\n",
            "Every effort moves you                                                  \n",
            "Ep 6 (Step 000050): Train loss 4.520, Val loss 6.386\n",
            "Ep 6 (Step 000055): Train loss 4.223, Val loss 6.219\n",
            "Every effort moves you                                                  \n",
            "Ep 7 (Step 000060): Train loss 3.980, Val loss 6.144\n",
            "Ep 7 (Step 000065): Train loss 3.348, Val loss 6.140\n",
            "Every effort moves you know, I had to the        \"--as, I had been.       \"I had the fact-rooms, and to my dear, and he had been.   \n",
            "Ep 8 (Step 000070): Train loss 2.881, Val loss 6.158\n",
            "Ep 8 (Step 000075): Train loss 2.481, Val loss 6.146\n",
            "Every effort moves you know,  \" to have all his pictures--            \"--as he was a little of an, and Mrs.          \"Oh, and\n",
            "Ep 9 (Step 000080): Train loss 2.211, Val loss 6.166\n",
            "Ep 9 (Step 000085): Train loss 1.834, Val loss 6.180\n",
            "Every effort moves you know, I seemed to the    \"Oh, and I was no--for it was not till, and his painting him, and left alone with him. I had always            \n",
            "Ep 10 (Step 000090): Train loss 1.611, Val loss 6.198\n",
            "Ep 10 (Step 000095): Train loss 1.195, Val loss 6.297\n",
            "Every effort moves you know, I seemed to see a smile behind his close     \"--for it was not till after that, on       \"I wish you'd tell me how it, with equanimity. \n",
            "Training completed in 24.91 minutes.\n"
          ]
        }
      ],
      "source": [
        "# Note:\n",
        "# Uncomment the following code to calculate the execution time\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Note\n",
        "# Uncomment the following code to show the execution time\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKlnCPMES8ZB"
      },
      "source": [
        "As we can see, based on the results printed during the training, the training loss improves\n",
        "drastically, starting with a value of 9.781 and converging to 0.391.\n",
        "\n",
        "The language skills of\n",
        "the model have improved quite a lot. In the beginning, the model is only able to append\n",
        "commas to the start context (\"Every effort moves you,,,,,,,,,,,,\") or repeat the\n",
        "word \"and\".\n",
        "\n",
        "At the end of the training, it can generate grammatically correct text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHW80UJCS8ZD"
      },
      "source": [
        "Similar to the training set loss, we can see that the validation loss starts high (9.856)\n",
        "and decreases during the training.\n",
        "\n",
        "However, it never becomes as small as the training set\n",
        "loss and remains at 6.372 after the 10th epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLW81BCPS8ZD"
      },
      "source": [
        "Let's create a simple plot that shows the training and validation set losses side by side"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYi7OeizS8ZE",
        "outputId": "f8e66d86-89a6-42cd-8295-a37f0728b983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX1_a5KWS8ZE"
      },
      "source": [
        "Both the training and validation losses start to improve for the first\n",
        "epoch. However, the losses start to diverge past the second epoch.\n",
        "\n",
        "This divergence and the\n",
        "fact that the validation loss is much larger than the training loss indicate that the model is\n",
        "overfitting to the training data.\n",
        "\n",
        "We can confirm that the model memorizes the training data\n",
        "verbatim by searching for the generated text snippets, such as \"quite insensible to the\n",
        "irony\" in the \"The Verdict\" text file.\n",
        "\n",
        "\n",
        "This memorization is expected since we are working with a very, very small training\n",
        "dataset and training the model for multiple epochs.\n",
        "\n",
        "Usually, it's common to train a model\n",
        "on a much, much larger dataset for only one epoch.   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Notes**"
      ],
      "metadata": {
        "id": "poUAcpNbY5SR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizers Used in LLM Training"
      ],
      "metadata": {
        "id": "Yjow1tlZY-OO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Large Language Models (LLMs) rely on gradient-based optimization, where optimizers adjust billions of parameters to minimize the loss.\n",
        "The most common optimizers are **Adam** and its improved variants.\n",
        "\n",
        "| **Optimizer**         | **Description**                                                                                                  | **Used In**                      |\n",
        "| --------------------- | ---------------------------------------------------------------------------------------------------------------- | -------------------------------- |\n",
        "| **Adam**              | Adaptive Moment Estimation — combines *momentum* and *RMSProp* ideas to adapt learning rates for each parameter. | BERT, GPT-2                      |\n",
        "| **AdamW**             | Adam with **decoupled weight decay**, improving generalization and training stability.                           | GPT-3, GPT-4, LLaMA              |\n",
        "| **Lion**              | Lightweight optimizer using only the **sign of momentum** for updates — faster and more memory-efficient.        | Newer research (Meta, 2023–2024) |\n",
        "| **Adafactor**         | Memory-efficient Adam variant — factorizes large parameter matrices.                                             | T5, PaLM                         |\n",
        "| **SGD with Momentum** | Simple and stable, but converges slower in high-dimensional settings.                                            | Smaller or older models          |\n",
        "\n",
        "\n",
        "**Example: AdamW Update Rule**\n",
        "\n",
        "> The **AdamW optimizer** is a key improvement over Adam.\n",
        "> It decouples *weight decay* from the gradient update, improving convergence and avoiding bias in L2 regularization.\n",
        "\n",
        "**Update Equations**\n",
        "\n",
        "At iteration (t)\n",
        "\n",
        "$$ m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t $$\n",
        "$$ v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 $$\n",
        "$$ \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t} $$\n",
        "$$ \\hat{v}*t = \\frac{v_t}{1 - \\beta_2^t} $$\n",
        "$$ \\theta*{t+1} = \\theta_t - \\eta \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} - \\eta \\lambda \\theta_t $$\n",
        "\n",
        "\n",
        "\n",
        "**Explanation of Terms**\n",
        "\n",
        "| Symbol                   | Meaning                                                       |\n",
        "| ------------------------ | ------------------------------------------------------------- |\n",
        "| ( g_t )                  | Gradient of loss with respect to parameters at step (t)       |\n",
        "| ( m_t )                  | Exponentially decaying average of past gradients (momentum)   |\n",
        "| ( v_t )                  | Exponentially decaying average of past squared gradients      |\n",
        "| ( \\beta_1, \\beta_2 )     | Hyperparameters controlling decay rates (typical: 0.9, 0.999) |\n",
        "| ( \\hat{m}_t, \\hat{v}_t ) | Bias-corrected estimates of (m_t) and (v_t)                   |\n",
        "| ( \\eta )                 | Learning rate                                                 |\n",
        "| ( \\lambda )              | Weight decay coefficient (regularization term)                |\n",
        "| ( \\epsilon )             | Small constant for numerical stability                        |\n",
        "\n",
        "\n",
        "\n",
        "**How It Works Conceptually**\n",
        "\n",
        "1. **Compute gradient** ( g_t ) of the loss function.\n",
        "2. **Update moving averages:**\n",
        "\n",
        "   * ( m_t ): tracks gradient direction (momentum).\n",
        "   * ( v_t ): tracks gradient magnitude (RMS normalization).\n",
        "3. **Bias-correct** both to account for initialization effects.\n",
        "4. **Update parameters:** move opposite to the gradient direction, with adaptive step size.\n",
        "5. **Apply weight decay:** regularize parameters to prevent overfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "Dkk4CVZnY8AM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimization Challanges"
      ],
      "metadata": {
        "id": "32853RuEaG1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Challenge                         | Description                                          | Mitigation                                             |\n",
        "| --------------------------------- | ---------------------------------------------------- | ------------------------------------------------------ |\n",
        "| **Vanishing/Exploding Gradients** | Gradients become too small/large through deep layers | LayerNorm, residuals, gradient clipping                |\n",
        "| **Instability in FP16 precision** | Floating point rounding issues                       | Use BF16 or mixed-precision scaling                    |\n",
        "| **Huge Memory Usage**             | Billions of parameters & optimizer states            | ZeRO optimizer, sharded training                       |\n",
        "| **Slow Convergence**              | Needs trillions of tokens                            | Adaptive LR, batch normalization, large-batch training |\n",
        "| **Catastrophic Forgetting**       | During fine-tuning, model forgets pretraining        | Low LR, regularization, LoRA adapters                  |\n"
      ],
      "metadata": {
        "id": "l8SQWwP_aJOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Learning Rate Schedules**"
      ],
      "metadata": {
        "id": "ASKbeL1caVU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **learning rate (LR)** controls *how big a step* the optimizer takes when updating weights.\n",
        "If the step is **too big → unstable / divergence**,\n",
        "if **too small → slow learning**.\n",
        "\n",
        "So, instead of keeping it constant, LLMs **change it gradually during training** — this is called a **learning rate schedule**.\n",
        "\n",
        "---\n",
        "\n",
        "Common Learning Rate Schedules\n",
        "\n",
        "| **Schedule**              | **What It Does**                                                                                                       | **How It Helps**                                                    | **Used In**                |\n",
        "| ------------------------- | ---------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------- | -------------------------- |\n",
        "| **Warmup + Cosine Decay** | Start with a small LR <br> (warmup), then slowly<br> increase, and finally<br> decrease in a smooth<br> wave-like curve <br>(cosine shape). | Prevents instability at the<br> start and fine-tunes slowly <br>at the end. | GPT, LLaMA                 |\n",
        "| **Linear Decay**          | Increases LR during<br> warmup, then gradually<br> decreases it linearly to <br>zero.                                              | Simple and stable for<br> most models.                                  | BERT, RoBERTa              |\n",
        "| **Step Decay**            | Keeps LR constant for<br> a few epochs, then<br> suddenly reduces it<br> (like steps).                                             | Older technique, less smooth.                                       | Early deep learning models |\n"
      ],
      "metadata": {
        "id": "G0XWqEBfaVwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why “Warmup”?**\n",
        "\n",
        "\n",
        "At the very beginning of training\n",
        "\n",
        "* The model’s weights are random.\n",
        "* Gradients (the learning signals) can be **unstable or huge**.\n",
        "\n",
        "If you start with a large learning rate, these large gradients can **blow up the weights** → training fails.\n",
        "\n",
        "So, we **“warm up”** by\n",
        "\n",
        "* starting with a very small learning rate,\n",
        "* gradually increasing it for the first few thousand steps,\n",
        "* then switching to a decay schedule.\n",
        "\n",
        "Think of it like\n",
        "\n",
        "> 🚗 “Don’t go from 0 to 100 immediately — start slow, then accelerate.”\n",
        "\n"
      ],
      "metadata": {
        "id": "izwoK3o4aVzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Optimization Techniques"
      ],
      "metadata": {
        "id": "DRf6yTgca_e_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a massive model like GPT means working with **billions of parameters** and **huge gradients**.\n",
        "So researchers use a few **tricks** to make training stable, efficient, and possible even with limited GPU memory.\n",
        "\n",
        "**Key Techniques Explained Simply**\n",
        "\n",
        "| **Technique**                                  | **What It Means (Beginner Explanation)**                                                                                                          | **Why It’s Used**                                                              |\n",
        "| ---------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------ |\n",
        "| **Gradient Clipping**                          | If the gradient (update signal) is too large,<br> we “clip” or limit its size.                                                                        | Prevents the model from making wild,<br> unstable updates (“exploding gradients”). |\n",
        "| **Gradient Accumulation**                      | Instead of using a huge batch at once <br>(which doesn’t fit in memory), we process<br> several small batches, sum their gradients, <br>and then update once. | Simulates large-batch training even on smaller<br> GPUs.                           |\n",
        "| **Mixed Precision Training (FP16 / BF16)**     | Uses smaller floating-point numbers <br>(16-bit instead of 32-bit) for faster math <br>and less memory use — while keeping<br> accuracy.                      | Makes training faster and reduces GPU memory<br> use.                              |\n",
        "| **Distributed Gradient Averaging (DDP)**       | When training on multiple GPUs or <br> machines, each computes its gradients,<br> and then all gradients are averaged <br>together.                            | Ensures all GPUs learn the same way<br> (synchronized training).                   |\n",
        "| **ZeRO Optimizer (Zero Redundancy Optimizer)** | Splits up the optimizer’s big memory states<br> across GPUs instead of duplicating them.                                                              | Allows models with *trillions* of parameters to fit <br>in GPU memory.             |\n",
        "| **Checkpointing (Activation Recomputation)**   | Instead of saving every activation in<br> memory, we recompute some of them <br>during backpropagation.                                                   | Saves memory — trades a bit of speed for<br> huge memory savings.                  |\n",
        "\n",
        "\n",
        "\n",
        "**Simple Real-World Analogy**\n",
        "\n",
        "| Technique             | Analogy                                                                          |\n",
        "| --------------------- | -------------------------------------------------------------------------------- |\n",
        "| Gradient Clipping     | Like limiting the maximum speed of a car to avoid crashing.                      |\n",
        "| Gradient Accumulation | Like carrying 10 small boxes one by one instead of 1 huge box.                   |\n",
        "| Mixed Precision       | Like using lighter materials that still get the job done.                        |\n",
        "| DDP                   | Like multiple chefs cooking the same recipe and comparing notes to stay in sync. |\n",
        "| ZeRO                  | Like dividing grocery bags among friends so no one carries too much.             |\n",
        "| Checkpointing         | Like not remembering every step, but redoing a few to save brain space.          |\n"
      ],
      "metadata": {
        "id": "ghBElep7a-bC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advanced Optimization Techniques (Modern Trends)"
      ],
      "metadata": {
        "id": "hjVdcQrYmC8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **LoRA (Low-Rank Adaptation)**\n",
        "\n",
        "What It Is\n",
        "\n",
        "> LoRA is a clever way to fine-tune large language models **without changing all of their billions of weights**.\n",
        "> Instead, it adds a few **tiny trainable layers** (small matrices) inside the model.\n",
        "\n",
        "So during fine-tuning:=\n",
        "\n",
        "* The **main model stays frozen** (unchanged)\n",
        "* Only the **small LoRA layers** are trained\n",
        "\n",
        "Intuition\n",
        "\n",
        "> Think of the big model as a **frozen brain**, and LoRA as adding a **small patch of new neurons** that learn the new skill.\n",
        "\n",
        "Why It’s Useful\n",
        "\n",
        "* Much faster fine-tuning\n",
        "* Needs **way less GPU memory**\n",
        "* You can train multiple versions (for different tasks) cheaply\n",
        "\n",
        "Example\n",
        "> Fine-tune a 70B model for a medical chatbot — instead of training all 70B parameters, you just train maybe 10M LoRA parameters.\n",
        "\n",
        "Used In\n",
        "\n",
        "> LLaMA, Falcon, Mistral, and most modern instruction-tuned or domain-specific LLMs.\n",
        "\n",
        "---\n",
        "2. **QLoRA (Quantized LoRA)**\n",
        "\n",
        "What It Is:\n",
        "\n",
        "> An improved version of LoRA that uses **quantization** — storing model weights in **4-bit numbers** (instead of 16-bit or 32-bit).\n",
        "> That’s a massive compression\n",
        "> 32-bit → 4-bit = 8× smaller memory use\n",
        "\n",
        "QLoRA fine-tunes these **compressed models** using the same LoRA idea.\n",
        "\n",
        "Intuition\n",
        "\n",
        "> Imagine fitting a huge encyclopedia into your phone by **compressing** it — but you can still read and update parts of it efficiently.\n",
        "\n",
        "Why It’s Useful\n",
        "\n",
        "* Lets you fine-tune **very large models (65B+) on a single GPU**.\n",
        "* Retains almost the same accuracy as full-precision training.\n",
        "* Ideal for researchers or smaller teams with limited hardware.\n",
        "\n",
        "Example:\n",
        "> Fine-tuning a 33B model on a **24GB RTX 4090** GPU — possible with QLoRA!\n",
        "\n",
        "Used In:\n",
        "\n",
        "> Alpaca, Vicuna, and many open-source fine-tuned LLMs.\n",
        "\n",
        "---\n",
        "\n",
        "3. **PEFT (Parameter-Efficient Fine-Tuning)**\n",
        "\n",
        "What It Is\n",
        "\n",
        "> PEFT is a **general family** of methods (including LoRA, Prefix-Tuning, Adapter-Tuning, etc.)\n",
        "> The goal: fine-tune large models by **updating only a small subset of parameters**.\n",
        "\n",
        "Intuition:\n",
        "\n",
        "> Instead of repainting an entire building (full fine-tuning), you **repaint only a few key walls** (PEFT).\n",
        "> The rest stays as it is.\n",
        "\n",
        "Why It’s Useful\n",
        "\n",
        "* Reduces training time ⏱️\n",
        "* Requires much less memory 💾\n",
        "* Keeps the original knowledge intact\n",
        "* Easy to switch between multiple tasks quickly\n",
        "\n",
        "Example\n",
        "\n",
        "A base LLM can be fine-tuned into\n",
        "* A medical assistant\n",
        "* A legal assistant\n",
        "* A coding helper\n",
        "  Each fine-tune just adds a **small PEFT adapter**, not a whole new model.\n",
        "\n",
        "Used In\n",
        "\n",
        "> All efficient fine-tuning libraries (Hugging Face PEFT, LoRA, QLoRA, Prefix Tuning).\n",
        "\n",
        "---\n",
        "\n",
        "4. **DPO / PPO (for Alignment via RLHF)**\n",
        "\n",
        "> These are **optimization methods used during alignment** — when the model is trained to **follow human preferences** (this is part of **RLHF – Reinforcement Learning from Human Feedback**).\n",
        "\n",
        "Step-by-Step Idea\n",
        "\n",
        "1. You first train a model to predict the next token (pretraining).\n",
        "2. Then fine-tune it to follow instructions (SFT).\n",
        "3. Finally, you *align* it using feedback from humans — this is where **PPO or DPO** comes in.\n",
        "\n",
        "---\n",
        "\n",
        "PPO — *Proximal Policy Optimization*\n",
        "\n",
        "* Comes from reinforcement learning.\n",
        "* The model is treated like a “policy” that chooses words.\n",
        "* It’s rewarded for producing responses humans prefer.\n",
        "* The **KL penalty** ensures it doesn’t drift too far from the base model.\n",
        "\n",
        "Analogy\n",
        "\n",
        "> Teaching a child: reward answers that sound polite and correct; gently discourage wrong or rude ones.\n",
        "\n",
        "---\n",
        "DPO — *Direct Preference Optimization*\n",
        "\n",
        "* A newer, simpler alternative to PPO.\n",
        "* Trains directly on pairs of responses (good vs bad).\n",
        "* No need for a separate reward model — it’s built into the math.\n",
        "* Easier and more stable to train.\n",
        "\n",
        "Analogy\n",
        "\n",
        "> Show the model two answers — “A” and “B” — and tell it, “A is better.” The model learns to prefer answers like A in the future.\n",
        "\n",
        "\n",
        "\n",
        "Why They Matter\n",
        "\n",
        "* Aligns LLM behavior with **human expectations**\n",
        "* Prevents harmful, rude, or irrelevant responses\n",
        "* Used in models like **ChatGPT, Claude, Gemini**\n",
        "\n",
        "---\n",
        "\n",
        "5. **Gradient Checkpointing**\n",
        "\n",
        "What It Is:\n",
        "\n",
        "> A memory-saving trick used during **training very deep models** (like 100+ transformer layers).\n",
        "> Normally, training stores *all intermediate activations* for backpropagation.\n",
        "That’s huge — it eats tons of GPU memory.\n",
        "> With **gradient checkpointing**, we:\n",
        "\n",
        "* Save only some activations,\n",
        "* Recompute the rest during backpropagation.\n",
        "\n",
        "> This trades **extra computation** for **massive memory savings**.\n",
        "\n",
        "Intuition\n",
        "\n",
        "> Imagine you’re hiking a trail and forget some landmarks.\n",
        "> Instead of carrying a big map (memory), you **retrace a few steps** (extra compute) to find your way back.\n",
        "\n",
        "Why It’s Useful\n",
        "* Saves **50–70% GPU memory**.\n",
        "* Makes training deep transformers possible on limited hardware.\n",
        "* Commonly used in GPT, LLaMA, and almost all large-scale models.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fK-LkWQzb61n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQp_Z85SS8ZE"
      },
      "source": [
        "# **DECODING STRATEGIES TO CONTROL RANDOMNESS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xfWnuu0S8ZE"
      },
      "source": [
        "First, we briefly revisit the generate_text_simple function\n",
        "from the previous chapter that we used inside the generate_and_print_sample earlier in\n",
        "this chapter.\n",
        "\n",
        "Then, we will cover two techniques, temperature scaling, and top-k sampling,\n",
        "to improve this function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qm4SXOES8ZE"
      },
      "source": [
        "We begin by transferring the model back from the GPU to the CPU since inference with a\n",
        "relatively small model does not require a GPU. Also, after training, we put the model into\n",
        "evaluation model to turn off random components such as dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwkp4IgzS8ZE",
        "outputId": "35cb224a-e916-471e-b1e6-f0831caa811b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuiO7aMJS8ZF"
      },
      "source": [
        "Next, we plug the GPTModel instance (model) into the generate_text_simple function,\n",
        "which uses the LLM to generate one token at a time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBXwXUSaS8ZF",
        "outputId": "476bac92-eafc-44c9-ffa2-abebc7a5ee7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you know, I seemed to see a smile behind his close\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\"--for it was not till after that\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=25,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgMMFI3xS8ZF"
      },
      "source": [
        "## **DECODING STRATEGY 1: TEMPERATURE SCALING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi2aDStTS8ZF"
      },
      "source": [
        "Previously, inside the generate_text_simple function, we always sampled the token\n",
        "with the highest probability as the next token using torch.argmax, also known as greedy\n",
        "decoding.\n",
        "\n",
        "To generate text with more variety, we can replace the argmax with a function\n",
        "that samples from a probability distribution (here, the probability scores the LLM generates\n",
        "for each vocabulary entry at each token generation step)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR6KV7LGS8ZF"
      },
      "source": [
        "To illustrate the probabilistic sampling with a concrete example, let's briefly discuss the\n",
        "next-token generation process using a very small vocabulary for illustration purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sG3dqVvS8ZG"
      },
      "outputs": [],
      "source": [
        "vocab = {\n",
        "    \"closer\": 0,\n",
        "    \"every\": 1,\n",
        "    \"effort\": 2,\n",
        "    \"forward\": 3,\n",
        "    \"inches\": 4,\n",
        "    \"moves\": 5,\n",
        "    \"pizza\": 6,\n",
        "    \"toward\": 7,\n",
        "    \"you\": 8,\n",
        "}\n",
        "\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msBIsGnQS8ZG"
      },
      "source": [
        "Next, assume the LLM is given the start context \"every effort moves you\" and\n",
        "generates the following next-token logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyTDO_H_S8ZG"
      },
      "outputs": [],
      "source": [
        "next_token_logits = torch.tensor(\n",
        "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgLy8jSrS8ZG"
      },
      "source": [
        "As discussed in the previous chapter, inside the generate_text_simple, we convert the\n",
        "logits into probabilities via the softmax function and obtain the token ID corresponding the\n",
        "generated token via the argmax function, which we can then map back into text via the\n",
        "inverse vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBwvx0_pS8ZG",
        "outputId": "fbf78a3f-c336-4b1d-983c-c184716f8887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n"
          ]
        }
      ],
      "source": [
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "next_token_id = torch.argmax(probas).item()\n",
        "print(inverse_vocab[next_token_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgUcOHrsS8ZG"
      },
      "source": [
        "To implement a probabilistic sampling process, we can now replace the argmax with the\n",
        "multinomial function in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8CN2-0rS8ZG",
        "outputId": "cea5468a-65cf-442f-a2d0-3496c077f22d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "print(inverse_vocab[next_token_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeQRT5NzS8ZG"
      },
      "source": [
        "The printed output is \"forward\" just like before. What happened? The multinomial\n",
        "function samples the next token proportional to its probability score.\n",
        "\n",
        "In other words,\n",
        "\"forward\" is still the most likely token and will be selected by multinomial most of the\n",
        "time but not all the time.\n",
        "\n",
        "To illustrate this, let's implement a function that repeats this\n",
        "sampling 1000 times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsAlHq91S8ZH",
        "outputId": "55b2bc5f-4f54-48ca-eacb-a705d7486f69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73 x closer\n",
            "0 x every\n",
            "0 x effort\n",
            "582 x forward\n",
            "2 x inches\n",
            "0 x moves\n",
            "0 x pizza\n",
            "343 x toward\n"
          ]
        }
      ],
      "source": [
        "def print_sampled_tokens(probas):\n",
        "    torch.manual_seed(123) # Manual seed for reproducibility\n",
        "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
        "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
        "    for i, freq in enumerate(sampled_ids):\n",
        "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
        "\n",
        "print_sampled_tokens(probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGkkM1V_S8ZH"
      },
      "source": [
        "As we can see based on the output, the word \"forward\" is sampled most of the time (582\n",
        "out of 1000 times), but other tokens such as \"closer\", \"inches\", and \"toward\" will also\n",
        "be sampled some of the time.\n",
        "\n",
        "This means that if we replaced the argmax function with the\n",
        "multinomial function inside the generate_and_print_sample function, the LLM would\n",
        "sometimes generate texts such as \"every effort moves you toward\", \"every effort\n",
        "moves you inches\", and \"every effort moves you closer\" instead of \"every effort\n",
        "moves you forward\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNZPUPsfS8ZH"
      },
      "source": [
        "We can further control the distribution and selection process via a concept called\n",
        "temperature scaling, where temperature scaling is just a fancy description for dividing the\n",
        "logits by a number greater than 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ4fwaBcS8ZH"
      },
      "source": [
        "Temperatures greater than 1 result in more uniformly distributed token probabilities,\n",
        "and Temperatures smaller than 1 will result in more confident (sharper or more peaky)\n",
        "distributions.\n",
        "\n",
        "Let's illustrate this by plotting the original probabilities alongside\n",
        "probabilities scaled with different temperature values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A25ENPuMS8ZH"
      },
      "outputs": [],
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        "    scaled_logits = logits / temperature\n",
        "    return torch.softmax(scaled_logits, dim=0)\n",
        "\n",
        "# Temperature values\n",
        "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
        "\n",
        "# Calculate scaled probabilities\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDSwd4sAS8ZH",
        "outputId": "8dc6f08c-708b-4b16-ab61-8979465308cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "for i, T in enumerate(temperatures):\n",
        "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
        "\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"temperature-plot.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d1ofY0MS8ZH"
      },
      "source": [
        "A temperature of 1 divides the logits by 1 before passing them to the softmax function to\n",
        "compute the probability scores.\n",
        "\n",
        "In other words, using a temperature of 1 is the same as not\n",
        "using any temperature scaling.\n",
        "\n",
        "In this case, the tokens are selected with a probability equal\n",
        "to the original softmax probability scores via the multinomial sampling function in PyTorch.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ359sB9S8ZI"
      },
      "source": [
        "Applying very small temperatures, such as 0.1, will\n",
        "result in sharper distributions such that the behavior of the multinomial function selects\n",
        "the most likely token (here: \"forward\") almost 100% of the time, approaching the\n",
        "behavior of the argmax function.\n",
        "\n",
        "Vice versa, a temperature of 5 results in a more uniform\n",
        "distribution where other tokens are selected more often.\n",
        "\n",
        "This can add more variety to the\n",
        "generated texts but also more often results in nonsensical text.\n",
        "\n",
        "For example, using the\n",
        "temperature of 5 results in texts such as \"every effort moves you pizza\" about 4% of\n",
        "the time."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TrqMil4yf3zF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxXrBRD-fsHt"
      },
      "source": [
        "## **DECODING STRATEGY 2: Top-k sampling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7RfqtSVfsHt"
      },
      "source": [
        "In the previous section, we implemented a probabilistic sampling approach coupled with\n",
        "temperature scaling to increase the diversity of the outputs.\n",
        "\n",
        "We saw that higher\n",
        "temperature values result in more uniformly distributed next-token probabilities, which\n",
        "result in more diverse outputs as it reduces the likelihood of the model repeatedly selecting\n",
        "the most probable token.\n",
        "\n",
        "This method allows for exploring less likely but potentially more\n",
        "interesting and creative paths in the generation process.\n",
        "\n",
        "However, One downside of this\n",
        "approach is that it sometimes leads to grammatically incorrect or completely nonsensical\n",
        "outputs such as \"every effort moves you pizza\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GC6PounfsHt"
      },
      "source": [
        "In this section, we introduce another concept called top-k sampling, which, when\n",
        "combined with probabilistic sampling and temperature scaling, can improve the text\n",
        "generation results.\n",
        "\n",
        "In top-k sampling, we can restrict the sampled tokens to the top-k most likely tokens\n",
        "and exclude all other tokens from the selection process by masking their probability scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRWuLdZJfsHu",
        "outputId": "bd0c44a3-c272-4ef6-c574-69168038aac2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
            "Top positions: tensor([3, 7, 0])\n"
          ]
        }
      ],
      "source": [
        "top_k = 3\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "print(\"Top logits:\", top_logits)\n",
        "print(\"Top positions:\", top_pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I67-JgOUfsHu"
      },
      "source": [
        "Subsequently, we apply PyTorch's where function to set the logit values of tokens that are\n",
        "below the lowest logit value within our top-3 selection to negative infinity (-inf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1OVF1k1fsHu",
        "outputId": "e8a82bb6-41a8-4633-90d6-54e400d5e3df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ],
      "source": [
        "new_logits = torch.where(\n",
        "    condition=next_token_logits < top_logits[-1],\n",
        "    input=torch.tensor(float(\"-inf\")),\n",
        "    other=next_token_logits\n",
        ")\n",
        "\n",
        "print(new_logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr0HnV6KfsHu"
      },
      "source": [
        "Lastly, let's apply the softmax function to turn these into next-token probabilities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rOKVkFgfsHu",
        "outputId": "098a7ec3-08cd-4161-e913-272e7fbff1e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ],
      "source": [
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "print(topk_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRH5NKS2fsHu"
      },
      "source": [
        "## **Merge Temperature Scaling and Top-k sampling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTeX0dHqfsHu"
      },
      "source": [
        "We can now apply the temperature scaling and multinomial function for probabilistic\n",
        "sampling introduced in the previous section to select the next token among these 3 nonzero probability scores to generate the next token. We do this in the next section by\n",
        "modifying the text generation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSanyIrofsHu"
      },
      "source": [
        "The previous two subsections introduced two concepts to increase the diversity of LLMgenerated text: temperature sampling and top-k sampling. In this section, we combine and\n",
        "add these concepts to modify the generate_simple function we used to generate text via\n",
        "the LLM earlier, creating a new generate function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvwLEnvMfsHv"
      },
      "source": [
        "Step 1: For-loop is the same as before: Get logits, and only focus on last time step\n",
        "\n",
        "Step 2: In this new section, we filter logits with top_k sampling\n",
        "\n",
        "Step 3: This is the new section where we apply temperature scaling\n",
        "    \n",
        "Step 4: Carry out greedy next-token selection as before when temperature scaling is disabled\n",
        "\n",
        "Step 5: Stop generating early if end-of-sequence token is encountered and eos_id is specified"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mQTQzcVfsHv"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ6itLfLfsHv"
      },
      "source": [
        "Let's now see this new generate function in action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zaeVou2fsHv",
        "outputId": "00d2a7e4-1ea5-41b8-864f-5fadc0c28d7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves you stand to work on surprise, a one of us had gone with random-\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "    top_k=25,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wVMvho_fsHv"
      },
      "source": [
        "As we can see, the generated text is very different from the one we previously generated\n",
        "via the generate_simple function at the beginning of section 5.3 (\"Every effort moves\n",
        "you know,\" was one of the axioms he laid...!\"), which was a memorized passage\n",
        "from the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiWqzTKEfsHw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decoding Strategies in LLMs**\n"
      ],
      "metadata": {
        "id": "07oOfTadN8U1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When a **Large Language Model (LLM)** like GPT or LLaMA generates text, it predicts\n",
        "*“What’s the most likely next word given all previous words?”*\n",
        "<br>\n",
        "But there’s a catch\n",
        "LLMs don’t just output *one* word; they output a **probability distribution** over thousands of possible words (tokens).\n",
        "\n",
        "Decoding strategies control **how we choose the next word** from those probabilities."
      ],
      "metadata": {
        "id": "LdE84sUKOG5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **What Decoding Really Means**\n"
      ],
      "metadata": {
        "id": "QLYQMQ7wOKOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagine this\n",
        "\n",
        "```\n",
        "Input: \"The cat is\"\n",
        "Predictions:\n",
        "sleeping → 0.70\n",
        "running → 0.20\n",
        "eating  → 0.10\n",
        "```\n",
        "\n",
        "Now the model must decide — which one to pick?\n",
        "Different decoding strategies make this choice differently."
      ],
      "metadata": {
        "id": "BkBe2l8HOKz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Greedy Decoding**"
      ],
      "metadata": {
        "id": "xXG1v8JlOQQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Idea: Always pick the word with the *highest* probability.\n",
        "\n",
        "Example:\n",
        "\n",
        "```\n",
        "sleeping (0.7) → choose “sleeping”\n",
        "```\n",
        "\n",
        "> Output: “The cat is sleeping.”\n",
        "\n",
        "**Pros**\n",
        "\n",
        "* Simple and very fast\n",
        "* Always gives the same answer (deterministic)\n",
        "\n",
        "**Cons**\n",
        "\n",
        "* Can get repetitive (e.g., “the cat is sleeping sleeping sleeping…”)\n",
        "* Sometimes misses better long-term options\n",
        "\n",
        "**Use when:** you want short, factual, or code-like outputs where creativity isn’t needed.\n"
      ],
      "metadata": {
        "id": "bl9HPY-GOdro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **Beam Search**"
      ],
      "metadata": {
        "id": "VrhlbjfpOhVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Idea:** Keep multiple possible sentences at once — not just one.\n",
        "\n",
        "Let’s say *beam size = 3*:\n",
        "\n",
        "* The model keeps the 3 most likely sentence paths at each step.\n",
        "* It expands them, scores them, and keeps the best 3 again.\n",
        "* Finally, it chooses the most likely full sentence.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```\n",
        "Beams:\n",
        "1. The cat is sleeping.\n",
        "2. The cat is running fast.\n",
        "3. The cat is eating fish.\n",
        "```\n",
        "\n",
        "→ Model picks the best based on total probability.\n",
        "\n",
        "**Pros**\n",
        "\n",
        "* More balanced and accurate than greedy\n",
        "* Often gives smoother, grammatically correct text\n",
        "\n",
        "**Cons**\n",
        "\n",
        "* Slower (because it tries many paths)\n",
        "* Still may lack creativity\n",
        "* Can repeat phrases if beam size is too big\n",
        "\n",
        "**Used in:** translation models (e.g., Google Translate), summarization."
      ],
      "metadata": {
        "id": "qDHDaTboOnEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Top-k Sampling**\n",
        "\n",
        "**Idea:** Add controlled randomness.\n",
        "Instead of picking *only the top token*, choose randomly from the **top k tokens**.\n",
        "\n",
        "**Example:**\n",
        "If `k = 3`\n",
        "\n",
        "```\n",
        "sleeping (0.7)\n",
        "running (0.2)\n",
        "eating  (0.1)\n",
        "```\n",
        "\n",
        "→ Model randomly picks one from these 3.\n",
        "\n",
        "**Pros**\n",
        "\n",
        "* Adds creativity and variation\n",
        "* Reduces boring repetitive output\n",
        "\n",
        "**Cons**\n",
        "\n",
        "* Still somewhat random\n",
        "* Needs tuning (too high k = chaos, too low k = boring)\n",
        "\n",
        "**Used in:** story generation, role-playing chatbots, and poetry generation."
      ],
      "metadata": {
        "id": "c1yilNyEOtpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Top-p (Nucleus) Sampling**"
      ],
      "metadata": {
        "id": "zEljZ5S3Ov0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Idea:** Instead of a *fixed number* of words (like k), choose tokens until their **total probability ≥ p** (like 0.9).\n",
        "\n",
        "**Example**\n",
        "\n",
        "```\n",
        "sleeping (0.7) + running (0.2) = 0.9 → pick from [sleeping, running]\n",
        "```\n",
        "\n",
        "→ Model samples from only these.\n",
        "\n",
        "**Pros**\n",
        "\n",
        "* Automatically adapts to context (flexible)\n",
        "* Produces human-like, natural text\n",
        "\n",
        "**Cons**\n",
        "\n",
        "* Can still be inconsistent\n",
        "* Requires good choice of p (commonly 0.9 or 0.95)\n",
        "\n",
        "**Used in:** ChatGPT and modern conversational LLMs."
      ],
      "metadata": {
        "id": "4NQ1KwBKO1N2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Temperature Sampling**"
      ],
      "metadata": {
        "id": "GQBqWcYxO2bO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Idea** Control how “confident” or “creative” the model is by adjusting *temperature (T)*.\n",
        "\n",
        "* **Low T (< 1.0):** more focused and predictable\n",
        "* **High T (> 1.0):** more random and creative\n",
        "\n",
        "**Example**\n",
        "\n",
        "```\n",
        "At T = 0.5 → prefers top tokens strongly  \n",
        "At T = 1.5 → explores more varied words\n",
        "```\n",
        "\n",
        "**Pros**\n",
        "\n",
        "* Fine-tunes creativity vs accuracy\n",
        "* Works great combined with Top-p or Top-k\n",
        "\n",
        "**Cons**\n",
        "\n",
        "* Too high T = nonsense\n",
        "* Too low T = robotic text\n",
        "\n",
        "**Used when:** you want to control tone — factual (low T), or creative (high T)."
      ],
      "metadata": {
        "id": "7TrjDrVzO-5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Typical Sampling**"
      ],
      "metadata": {
        "id": "PU_UIvkqPCEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Idea:** Keeps words that are *“typical”* (close to model’s average surprise level).\n",
        "Removes\n",
        "\n",
        "* Words that are too common (boring)\n",
        "* Words that are too rare (weird)\n",
        "\n",
        "**Pros**\n",
        "\n",
        "* Natural, balanced, less repetitive text\n",
        "* Combines the best of Top-p and Temperature\n",
        "\n",
        "**Used in** modern chatbots like GPT-3.5, GPT-4 for conversational tone."
      ],
      "metadata": {
        "id": "u9gH1hlaPEwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **Contrastive Decoding**"
      ],
      "metadata": {
        "id": "1cqBE7sPPHQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Idea:** Uses two models\n",
        "\n",
        "* **Large model:** generates fluent text\n",
        "* **Small model:** filters out generic or overconfident text\n",
        "\n",
        "Formula\n",
        "$$\n",
        "\\text{score}(x) = P_{large}(x) - \\alpha \\times P_{small}(x)\n",
        "$$\n",
        "\n",
        "**Pros**\n",
        "\n",
        "* More factual and precise\n",
        "* Avoids hallucinations and repetition\n",
        "\n",
        "**Used in** factual Q&A, retrieval-based systems, and academic content.\n"
      ],
      "metadata": {
        "id": "0Ned7p1lPM9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sampling + Re-ranking**"
      ],
      "metadata": {
        "id": "T1Z32lEuPThZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Idea** Generate multiple possible outputs, then rank them with a *reward* or *critic model* (used in RLHF — Reinforcement Learning from Human Feedback).\n",
        "\n",
        "Example\n",
        "\n",
        "1. Generate 5 possible replies.\n",
        "2. Use a separate model to score them.\n",
        "3. Choose the one with the best score.\n",
        "\n",
        "**Pros**\n",
        "\n",
        "* Highest quality responses\n",
        "* Aligns with human preferences\n",
        "**Used in** ChatGPT and alignment training."
      ],
      "metadata": {
        "id": "YOgBmqTIPVak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Quick Analogy**\n",
        "\n",
        "Think of decoding like **ordering food from a restaurant** 🍽️:\n",
        "\n",
        "| Strategy             | Analogy                                                                      |\n",
        "| -------------------- | ---------------------------------------------------------------------------- |\n",
        "| **Greedy**           | Always order your favorite dish every time.                                  |\n",
        "| **Beam Search**      | Try 3 dishes, then pick the best one.                                        |\n",
        "| **Top-k**            | Choose randomly from your top 3 favorites.                                   |\n",
        "| **Top-p**            | Choose randomly from dishes that together make up 90% of your favorites.     |\n",
        "| **Temperature**      | Higher temperature → you experiment more; lower temperature → you play safe. |\n",
        "| **Typical Sampling** | You usually order something “normal” — not too basic, not too weird.         |\n",
        "| **Contrastive**      | You and your friend (small model) agree on what’s good before ordering.      |\n"
      ],
      "metadata": {
        "id": "CMZamvr6N6WB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGbgnPwBS8ZI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QkBo8w_TaHgE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo-2cJXTZ8lQ"
      },
      "source": [
        "# **LOADING AND SAVING MODEL WEIGHTS IN PYTORCH**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC6aDwzNZ8lQ"
      },
      "source": [
        "Fortunately, saving a PyTorch model is relatively straightforward.\n",
        "\n",
        "The recommended way is to save a model's so-called state_dict, a dictionary mapping each layer to its parameters,\n",
        "using the torch.save function as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7yryiNkZ8lQ"
      },
      "outputs": [],
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "torch.save(model.state_dict(), \"model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKAw3rWcZ8lQ"
      },
      "source": [
        "In the preceding code, \"model.pth\" is the filename where the state_dict is saved.\n",
        "\n",
        "The .pth extension is a convention for PyTorch files, though we could technically use any file\n",
        "extension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu9Fhs7KZ8lQ"
      },
      "source": [
        "Then, after saving the model weights via the `state_dict` we can load the model\n",
        "weights into a new GPTModel model instance as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgiAEZqSZ8lQ",
        "outputId": "3844bd10-2cb1-4480-a389-516f43b153ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 211,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wMUhUfgZ8lQ"
      },
      "source": [
        "If we plan to continue pretraining a model later, for example, using the\n",
        "train_model_simple function we defined earlier in this chapter, saving the optimizer state\n",
        "is also recommended."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNzSKYAnZ8lR"
      },
      "source": [
        "Adaptive optimizers such as AdamW store additional parameters for each model weight.\n",
        "AdamW uses historical data to adjust learning rates for each model parameter dynamically.\n",
        "                                                   \n",
        "Without it, the optimizer resets, and the model may learn suboptimally or even fail to\n",
        "converge properly, which means that it will lose the ability to generate coherent text.\n",
        "\n",
        "Using\n",
        "torch.save, we can save both the model and optimizer state_dict contents as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlk7dlPQZ8lR"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    \"model_and_optimizer.pth\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACX2mHowZ8lR"
      },
      "source": [
        "hen, we can restore the model and optimizer states as follows by first loading the saved\n",
        "data via torch.load and then using the load_state_dict method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH7kuhF4Z8lR"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS-9BNgVZ8lR"
      },
      "source": [
        "## **LOADING PRETRAINED WEIGHTS FROM OPENAI**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-61iWnR6Z8lR"
      },
      "source": [
        "Previously, for educational purposes, we trained a small GPT-2 model using a limited\n",
        "dataset comprising a short-story book.\n",
        "\n",
        "This approach allowed us to focus on the\n",
        "fundamentals without the need for extensive time and computational resources.\n",
        "\n",
        "    \n",
        "Fortunately, OpenAI openly shared the weights of their GPT-2 models, thus eliminating\n",
        "the need to invest tens to hundreds of thousands of dollars in retraining the model on a\n",
        "large corpus ourselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfchDlU9Z8lS"
      },
      "source": [
        "In the remainder of this section, we load these weights into our GPTModel class and use\n",
        "the model for text generation.\n",
        "\n",
        "Here, weights refer to the weight parameters that are stored\n",
        "in the .weight attributes of PyTorch's Linear and Embedding layers, for example.\n",
        "\n",
        "We accessed them earlier via model.parameters() when training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trjJsotNZ8lS"
      },
      "source": [
        "Note that OpenAI originally saved the GPT-2 weights via TensorFlow, which we have to\n",
        "install to load the weights in Python.\n",
        "\n",
        "Moreover, the following code will use a progress bar\n",
        "tool called tqdm to track the download process, which we also have to install."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUhBrTw5Z8lS",
        "outputId": "06be5c57-7ad5-4434-b247-ed57e84f1513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: 2.15.0 not found\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow>=2.15.0 tqdm>=4.66"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3MHDTX2Z8lS",
        "outputId": "797b0a49-7978-4c4a-9919-99efbcb7cc1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.16.1\n",
            "tqdm version: 4.66.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tqdm\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"tqdm version:\", tqdm.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8uWuW__Z8lS"
      },
      "source": [
        "We download the gpt_download.py Python module directly from this chapter's online repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqz7ThpvZ8lS"
      },
      "source": [
        "We can now import the download_and_load_gpt2 function from the gpt_download.py\n",
        "file as follows, which will load the GPT-2 architecture settings (settings) and weight\n",
        "parameters (params) into our Python session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTlIwhebZ8lS"
      },
      "outputs": [],
      "source": [
        "from gpt_download3 import download_and_load_gpt2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNPs6SaXZ8lT",
        "outputId": "8a62afa3-47a7-4de5-a4d0-785d3ddb656a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.data-00000-of-00001: 100%|████████████| 498M/498M [09:33<00:00, 868kiB/s]\n",
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.index: 100%|███████████████████████| 5.21k/5.21k [00:00<00:00, 6.57MiB/s]\n",
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.meta: 100%|███████████████████████████| 471k/471k [00:02<00:00, 223kiB/s]\n",
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "vocab.bpe: 100%|█████████████████████████████████| 456k/456k [00:02<00:00, 226kiB/s]\n"
          ]
        }
      ],
      "source": [
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJRU4mswZ8lT"
      },
      "source": [
        "After the execution of the previous code has been completed, let's inspect the contents of\n",
        "settings and params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyXYtxpSZ8lT",
        "outputId": "a525742d-e329-4153-a725-fcfed858d0a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ],
      "source": [
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXkyLtztZ8lT"
      },
      "source": [
        "Both settings and params are Python dictionaries. The settings dictionary stores the LLM\n",
        "architecture settings similarly to our manually defined GPT_CONFIG_124M settings.\n",
        "\n",
        "The\n",
        "params dictionary contains the actual weight tensors.\n",
        "\n",
        "    \n",
        "Note that we only printed the\n",
        "dictionary keys because printing the weight contents would take up too much screen space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8Rzru7fZ8lT"
      },
      "source": [
        "We can inspect these weight tensors by printing the whole dictionary via\n",
        "print(params) or by selecting individual tensors via the respective dictionary keys, for\n",
        "example, the embedding layer weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ujoUGxcZ8lU",
        "outputId": "d43608cd-8df7-4b29-ddfb-ec5f67f2280e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ],
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlxETHIWZ8lU"
      },
      "source": [
        "We downloaded and loaded the weights of the smallest GPT-2 model via the\n",
        "download_and_load_gpt2(model_size=\"124M\", ...) setting. However, note that OpenAI\n",
        "also shares the weights of larger models: \"355M\", \"774M\", and \"1558M\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcD1la-NZ8lU"
      },
      "source": [
        "Above, we loaded the 124M GPT-2 model weights into Python, however we still need to transfer them into our GPTModel instance.\n",
        "\n",
        "First, we initialize a new GPTModel instance.\n",
        "\n",
        "Note that the original GPT model initialized the linear layers for the query, key, and value matrices in the multi-head attention module with bias vectors, which is not required or recommended; however, to be able to load the weights correctly, we have to enable these too by setting qkv_bias to True in our implementation, too.\n",
        "                                                                                                                                                                                                                                                                                                                                  \n",
        "We are also using the 1024 token context length that was used by the original GPT-2 model(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lajXvJk-Z8lU"
      },
      "outputs": [],
      "source": [
        "# Define model configurations in a dictionary for compactness\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "# Copy the base configuration and update with specific model settings\n",
        "model_name = \"gpt2-small (124M)\"  # Example model name\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqLdyyhnZ8lU"
      },
      "source": [
        "Careful readers may remember that we used a 256-token length earlier, but the original\n",
        "GPT-2 models from OpenAI were trained with a 1,024-token length, so we have to update\n",
        "the NEW_CONFIG accordingly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9jW8XrsZ8lV"
      },
      "source": [
        "Also, OpenAI used bias vectors in the multi-head attention module's linear layers to\n",
        "implement the query, key, and value matrix computations.\n",
        "\n",
        "Bias vectors are not commonly\n",
        "used in LLMs anymore as they don't improve the modeling performance and are thus\n",
        "unnecessary.\n",
        "\n",
        "However, since we are working with pretrained weights, we need to match the\n",
        "settings for consistency and enable these bias vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_n62t3iZ8lV"
      },
      "outputs": [],
      "source": [
        "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-6FVs2pZ8lV"
      },
      "source": [
        "By default, the GPTModel instance is initialized with random weights for pretraining.\n",
        "\n",
        "The last\n",
        "step to using OpenAI's model weights is to override these random weights with the weights\n",
        "we loaded into the params dictionary.\n",
        "\n",
        "For this, we will first define a small assign utility function that checks whether two\n",
        "tensors or arrays (left and right) have the same dimensions or shape and returns the\n",
        "right tensor as trainable PyTorch parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk-TUz4UZ8lV"
      },
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gttI3pWnZ8lV"
      },
      "source": [
        "Next, we define a load_weights_into_gpt function that loads the weights from the params\n",
        "dictionary into a GPTModel instance gpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbQD_rn-Z8lV"
      },
      "source": [
        "Step 1: Setting the model's positional and token embedding weights to those specified in params.\n",
        "\n",
        "Step 2: Iterate over each transformer block in the model.\n",
        "\n",
        "Step 3: The np.split function is used to divide the attention and bias weights into three equal parts for the query,\n",
        "key, and value components.\n",
        "    \n",
        "Step 4: The original GPT-2 model by OpenAI reused the token embedding weights in the output layer to reduce the\n",
        "total number of parameters, which is a concept known as weight tying."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzbH0szNZ8lV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl1cF4ppZ8lW"
      },
      "source": [
        "In the load_weights_into_gpt function, we carefully match the weights from OpenAI's\n",
        "implementation with our GPTModel implementation.\n",
        "\n",
        "To pick a specific example, OpenAI\n",
        "stored the weight tensor for the output projection layer for the first transformer block as\n",
        "params[\"blocks\"][0][\"attn\"][\"c_proj\"][\"w\"].\n",
        "                                                        \n",
        "In our implementation, this weight\n",
        "tensor corresponds to gpt.trf_blocks[b].att.out_proj.weight, where gpt is a\n",
        "GPTModel instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAsKRoKqZ8lW"
      },
      "source": [
        "Developing the load_weights_into_gpt function took a lot of guesswork since OpenAI\n",
        "used a slightly different naming convention from ours.\n",
        "\n",
        "However, the assign function would\n",
        "alert us if we try to match two tensors with different dimensions.\n",
        "\n",
        "Also, if we made a\n",
        "mistake in this function, we would notice this as the resulting GPT model would be unable\n",
        "to produce coherent text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wStYBp5kZ8lW"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's now try the load_weights_into_gpt out in practice and load the OpenAI model\n",
        "weights into our GPTModel instance gpt:\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2_zxtVXZ8lW"
      },
      "outputs": [],
      "source": [
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gDqGvC1Z8lX"
      },
      "source": [
        "If the model is loaded correctly, we can now use it to generate new text using our previous\n",
        "generate function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drp5zOgRZ8lX",
        "outputId": "2b85d21d-5983-4f97-ed55-158bdd441325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves you toward finding an ideal new way to practice something!\n",
            "\n",
            "What makes us want to be on top of that?\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHo_KAaKZ8lX"
      },
      "source": [
        "We can be confident that we loaded the model weights correctly because the model can\n",
        "produce coherent text.\n",
        "\n",
        "A tiny mistake in this process would cause the model to fail.\n",
        "\n",
        "    \n",
        "In the following chapters, we will work further with this pretrained model and fine-tune it\n",
        "to classify text and follow instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVLfmachZ8lX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDpe_z7fTjEo"
      },
      "source": [
        "# **FINETUNING FOR CLASSIFICATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmOBm-n_TjEo"
      },
      "source": [
        "### **DOWNLOADING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkSfj0MWTjEo",
        "outputId": "06db6e53-300a-47a3-a575-1e995f3ae9c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import ssl\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # Create an unverified SSL context\n",
        "    ssl_context = ssl._create_unverified_context()\n",
        "\n",
        "    # Downloading the file\n",
        "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # Unzipping the file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # Add .tsv file extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iaDJg_eTjEo"
      },
      "source": [
        "After executing the preceding code, the dataset is saved as a tab-separated text file,\n",
        "SMSSpamCollection.tsv, in the sms_spam_collection folder.\n",
        "\n",
        "We can load it into a pandas\n",
        "DataFrame as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7ljUkEgTjEo",
        "outputId": "d98c53b9-b781-4d55-a0e3-ba5460c557ab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "execution_count": 231,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrLBGc-YTjEo"
      },
      "source": [
        "When we check the class distribution, we see that the data contains \"ham\" (i.e., \"not spam\") much more frequently than \"spam\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfFE22dkTjEo",
        "outputId": "9adbe1fd-2cc3-463f-f4b6-72ad14f4d1d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df[\"Label\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "namjxcexTjEo"
      },
      "source": [
        "For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzzPOT7MTjEp",
        "outputId": "25a87deb-e673-4de9-a626-560e76f6aa1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def create_balanced_dataset(df):\n",
        "\n",
        "    # Count the instances of \"spam\"\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "\n",
        "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "\n",
        "    # Combine ham \"subset\" with \"spam\"\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhEpH371TjEp"
      },
      "source": [
        "After executing the previous code to balance the dataset, we can see that we now have\n",
        "equal amounts of spam and non-spam messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a69s30XiTjEp"
      },
      "source": [
        "Next, we convert the \"string\" class labels \"ham\" and \"spam\" into integer class labels 0 and\n",
        "1, respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpDZzE7fTjEp"
      },
      "outputs": [],
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXQ6lNPUTjEp"
      },
      "source": [
        "This process is similar to converting text into token IDs.\n",
        "\n",
        "However, instead of using the GPT\n",
        "vocabulary, which consists of more than 50,000 words, we are dealing with just two token\n",
        "IDs: 0 and 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xctHPcdjTjEp"
      },
      "source": [
        "We create a random_split function to split the dataset into three parts: 70% for\n",
        "training, 10% for validation, and 20% for testing.\n",
        "\n",
        "(These ratios are common in machine\n",
        "learning to train, adjust, and evaluate models.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWEzVx4-TjEp"
      },
      "outputs": [],
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "    # Shuffle the entire DataFrame\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # Calculate split indices\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    # Split the DataFrame\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "# Test size is implied to be 0.2 as the remainder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUO0Htu0TjEp",
        "outputId": "894a6edd-a7d8-46c4-ca16-a547401b5c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1045\n",
            "149\n",
            "300\n"
          ]
        }
      ],
      "source": [
        "print(len(train_df))\n",
        "print(len(validation_df))\n",
        "print(len(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10avqSGDTjEq"
      },
      "source": [
        "Additionally, we save the dataset as CSV (comma-separated value) files, which we can\n",
        "reuse later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0VmcOp8TjEq"
      },
      "outputs": [],
      "source": [
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9EVT8WzTjEq"
      },
      "source": [
        "### **CREATING DATALOADERS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJqL3s0WTjEq"
      },
      "source": [
        "Previously, we utilized a sliding window technique to generate uniformly\n",
        "sized text chunks, which were then grouped into batches for more efficient model training.\n",
        "Each chunk functioned as an individual training instance\n",
        "\n",
        "In the case of email spam classification, have two primary options:\n",
        "\n",
        "(1) Truncate all messages to the length of the shortest message in the\n",
        "dataset or batch.\n",
        "\n",
        "(2) Pad all messages to the length of the longest message in the dataset or\n",
        "batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k79O0_pQTjEq"
      },
      "source": [
        "> Option 1 is computationally cheaper, but it may result in significant information loss if\n",
        "shorter messages are much smaller than the average or longest messages, potentially\n",
        "reducing model performance.\n",
        "\n",
        "So, we opt for the second option, which preserves the entire\n",
        "content of all messages.\n",
        "\n",
        "To implement option 2, where all messages are padded to the length of the longest\n",
        "message in the dataset, we add padding tokens to all shorter messages.\n",
        "\n",
        "For this purpose,\n",
        "we use \"<|endoftext|>\" as a padding token, as discussed in chapter 2.\n",
        "\n",
        "    \n",
        "However, instead of appending the string \"<|endoftext|>\" to each of the text messages\n",
        "directly, we can add the token ID corresponding to \"<|endoftext|>\" to the encoded text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icPBx1q1TjEq"
      },
      "source": [
        "As we have seen earlier, we first need to implement a PyTorch Dataset, which\n",
        "specifies how the data is loaded and processed, before we can instantiate the data loaders.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xni662tFTjEq"
      },
      "source": [
        "For this purpose, we define the SpamDataset class.\n",
        "\n",
        "This SpamDataset class handles several key tasks: it identifies the\n",
        "longest sequence in the training dataset, encodes the text messages, and ensures that all\n",
        "other sequences are padded with a padding token to match the length of the longest\n",
        "sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqYPvCE2TjEq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd  # Required for reading CSV files\n",
        "\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        \"\"\"\n",
        "        Custom PyTorch Dataset class for spam detection tasks.\n",
        "\n",
        "        Args:\n",
        "            csv_file (str): Path to the CSV file containing 'Text' and 'Label' columns.\n",
        "            tokenizer (object): Tokenizer used to convert text into token IDs.\n",
        "            max_length (int, optional): Maximum sequence length for each sample.\n",
        "                                        If None, it is set to the longest sequence found.\n",
        "            pad_token_id (int): Token ID used for padding shorter sequences.\n",
        "        \"\"\"\n",
        "        # Load the dataset from a CSV file\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Tokenize each text in the dataset and store the tokenized lists\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "        ]\n",
        "\n",
        "        # Determine the maximum sequence length\n",
        "        if max_length is None:\n",
        "            # Automatically set to the longest tokenized sequence\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            # Use the user-specified maximum sequence length\n",
        "            self.max_length = max_length\n",
        "\n",
        "            # Truncate any sequence longer than the maximum length\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # Pad all sequences so they have equal length (self.max_length)\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Retrieve a single sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "            index (int): Index of the sample to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (input_tensor, label_tensor)\n",
        "                   - input_tensor: Tensor of token IDs for the text.\n",
        "                   - label_tensor: Corresponding label (0 for ham, 1 for spam).\n",
        "        \"\"\"\n",
        "        # Get the encoded sequence\n",
        "        encoded = self.encoded_texts[index]\n",
        "\n",
        "        # Get the label for the given sample\n",
        "        label = self.data.iloc[index][\"Label\"]\n",
        "\n",
        "        # Convert both encoded text and label into PyTorch tensors\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "            torch.tensor(label, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Return the total number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        \"\"\"\n",
        "        Compute the length of the longest tokenized text in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: The maximum sequence length among all tokenized samples.\n",
        "        \"\"\"\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFSVClEsTjEq"
      },
      "source": [
        "Step 1: Pre-tokenize texts\n",
        "    \n",
        "Step 2: Truncate sequences if they are longer than max_length\n",
        "    \n",
        "Step 3: Pad sequences to the longest sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGs7VIo7TjEq"
      },
      "source": [
        "The SpamDataset class loads data from the CSV files we created earlier, tokenizes the text\n",
        "using the GPT-2 tokenizer from tiktoken and allows us to pad or truncate the sequences to\n",
        "a uniform length determined by either the longest sequence or a predefined maximum\n",
        "length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-1Fzw7RTjEr"
      },
      "source": [
        "This ensures each input tensor is of the same size, which is necessary to create the\n",
        "batches in the training data loader we implement next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEQdTBziTjEr",
        "outputId": "71c528dd-2e5d-4ff3-d249-1ac12780fc5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120\n"
          ]
        }
      ],
      "source": [
        "train_dataset = SpamDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(train_dataset.max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbNpchbKTjEr"
      },
      "source": [
        "The code outputs 120, showing that the longest sequence contains no more than 120\n",
        "tokens, a common length for text messages.\n",
        "                       \n",
        "It's worth noting that the model can handle\n",
        "sequences of up to 1,024 tokens, given its context length limit.\n",
        "\n",
        "If your dataset includes\n",
        "longer texts, you can pass max_length=1024 when creating the training dataset in the\n",
        "preceding code to ensure that the data does not exceed the model's supported input\n",
        "(context) length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwYz-5dZTjEs"
      },
      "source": [
        "Next, we pad the validation and test sets to match the length of the longest training\n",
        "sequence.\n",
        "\n",
        "It's important to note that any validation and test set samples exceeding the\n",
        "length of the longest training example are truncated using\n",
        "encoded_text[:self.max_length] in the SpamDataset code we defined earlier.\n",
        "\n",
        "This\n",
        "truncation is optional; you could also set max_length=None for both validation and test\n",
        "sets, provided there are no sequences exceeding 1,024 tokens in these sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWMT465STjEs",
        "outputId": "afbd6a28-708b-486b-9abc-28484b7662d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120\n"
          ]
        }
      ],
      "source": [
        "val_dataset = SpamDataset(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = SpamDataset(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(test_dataset.max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhyig4krTjEs"
      },
      "source": [
        "Using the datasets as inputs, we can instantiate the data loaders similarly to what we did earlier.\n",
        "\n",
        "However, in this case, the targets represent class labels rather than the next\n",
        "tokens in the text.\n",
        "\n",
        "For instance, choosing a batch size of 8, each batch will consist of 8\n",
        "training examples of length 120 and the corresponding class label of each example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGK00EeiTjEs"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiRkGtFKTjEs"
      },
      "source": [
        "To ensure that the data loaders are working and are indeed returning batches of the\n",
        "expected size, we iterate over the training loader and then print the tensor dimensions of\n",
        "the last batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTzs3t4DTjEs",
        "outputId": "4fc3f9a4-59d7-4050-ba7d-51d64ea44683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader:\n",
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass\n",
        "\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx2cdIb9TjEs"
      },
      "source": [
        "As we can see, the input batches consist of 8 training examples with 120 tokens each, as\n",
        "expected.\n",
        "\n",
        "The label tensor stores the class labels corresponding to the 8 training examples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGJXK4tRTjEs"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Lastly, to get an idea of the dataset size, let's print the total number of batches in each\n",
        "dataset:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByJjI69NTjEs",
        "outputId": "df7f3fbf-8729-4961-a176-0051ae9f84cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMI5u_KITjEs"
      },
      "source": [
        "This concludes the data preparation. Next, we will prepare the model for\n",
        "finetuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIsbhcL-TjEt"
      },
      "source": [
        "## **INITIALIZING A MODEL WITH PRETRAINED WEIGHTS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onSLfYp0TjEt"
      },
      "source": [
        "In this section, we prepare the model we will use for the classification-finetuning to identify\n",
        "spam messages.\n",
        "\n",
        "We start with initializing the pretrained model we worked with in the\n",
        "previous chapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qkib8pDTjEt"
      },
      "outputs": [],
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
        "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
        "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
        "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRs5lMztTjEt"
      },
      "source": [
        "Next, we import the download_and_load_gpt function from the gpt_download3.py file we\n",
        "downloaded earlier.\n",
        "\n",
        "Furthermore, we also reuse the GPTModel class and\n",
        "load_weights_into_gpt function from chapter 5 to load the downloaded weights into the\n",
        "GPT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf9g4bgNTjEt",
        "outputId": "a05c8122-b873-433e-f0bf-86ad075eacba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        }
      ],
      "source": [
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "\n",
        "from gpt_download3 import download_and_load_gpt2\n",
        "\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M553mQBTjEt"
      },
      "source": [
        "To ensure that the model was loaded correctly, let's double-check that it generates coherent text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "179kKoMwTjEt",
        "outputId": "48c95f9c-41e8-4f32-87f1-44e0d0eda2c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work\n"
          ]
        }
      ],
      "source": [
        "text_1 = \"Every effort moves you\"\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG7MHkISTjEt"
      },
      "source": [
        "Now, before we start finetuning the model as a spam classifier, let's see if the model can\n",
        "perhaps already classify spam messages by by prompting it with instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdVof5JmTjEt",
        "outputId": "63ed59b0-76e3-4ac2-89a7-5f4b66e3040a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
            "\n",
            "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "    \" 'You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_2, tokenizer),\n",
        "    max_new_tokens=23,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4BEoi8KTjEu"
      },
      "source": [
        "Based on the output, it's apparent that the model struggles with following instructions.\n",
        "\n",
        "This is anticipated, as it has undergone only pretraining and lacks instruction-finetuning,\n",
        "which we will explore in the upcoming chapter\n",
        "\n",
        "The next section prepares the model for classification-finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFEDA4NzTjEu"
      },
      "source": [
        "## **ADDING A CLASSIFICATION HEAD**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_r02sSCTjEu"
      },
      "source": [
        "In this section, we modify the pretrained large language model to prepare it for\n",
        "classification-finetuning.\n",
        "\n",
        "To do this, we replace the original output layer, which maps the\n",
        "hidden representation to a vocabulary of 50,257, with a smaller output layer that maps to\n",
        "two classes: 0 (\"not spam\") and 1 (\"spam\"),"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S5ziq42TjEu"
      },
      "source": [
        "We could technically use a single output node since we are dealing with a binary\n",
        "classification task.\n",
        "\n",
        "However, this would require modifying the loss function.\n",
        "\n",
        "Therefore, we choose a\n",
        "more general approach where the number of output nodes matches the number of\n",
        "classes.\n",
        "\n",
        "For example, for a 3-class problem, such as classifying news articles as\n",
        "\"Technology\", \"Sports\", or \"Politics\", we would use three output nodes, and so forth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEI_fPPiTjEu"
      },
      "source": [
        "Before we attempt to construct the modified architecture, let's print the model\n",
        "architecture via print(model), which prints the following"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ou1O5xgTjEu",
        "outputId": "c6add931-5c54-4c55-f433-9ca1ea195b93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51IR6LUyTjEu"
      },
      "source": [
        "Above, we can see the GPT architecture neatly laid out.\n",
        "\n",
        "As\n",
        "discussed earlier, the GPTModel consists of embedding layers followed by 12 identical\n",
        "transformer blocks (only the last block is shown for brevity), followed by a final LayerNorm\n",
        "and the output layer, out_head."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zniPRonTjEu"
      },
      "source": [
        "Next, we replace the out_head with a new output layer, as illustrated in figure 6.9, that\n",
        "we will finetune.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvYbIMBPTjEu"
      },
      "source": [
        "To get the model ready for classification-finetuning, we first freeze the model, meaning that\n",
        "we make all layers non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwSlsSHiTjEu"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0bG-Pf8TjEv"
      },
      "source": [
        "Then, we replace the output layer (model.out_head), which\n",
        "originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8o3K8ELTjEv"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srHDRcrETjEv"
      },
      "source": [
        "Note that in the preceding code, we use BASE_CONFIG[\"emb_dim\"], which is equal to 768 in\n",
        "the \"gpt2-small (124M)\" model, to keep the code below more general.\n",
        "\n",
        "This means we\n",
        "can also use the same code to work with the larger GPT-2 model variants.\n",
        "\n",
        "This new model.out_head output layer has its requires_grad attribute set to True by\n",
        "default, which means that it's the only layer in the model that will be updated during\n",
        "training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv57dxZrTjEv"
      },
      "source": [
        "This new model.out_head output layer has its requires_grad attribute set to True by\n",
        "default, which means that it's the only layer in the model that will be updated during\n",
        "training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNI5DVO5TjEv"
      },
      "source": [
        "Additionally, we configure the last transformer block and the final LayerNorm module,\n",
        "which connects this block to the output layer, to be trainable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybma5mmvTjEv"
      },
      "outputs": [],
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMooA0BlTjEv"
      },
      "source": [
        "Even though we added a new output layer and marked certain layers as trainable or nontrainable, we can still use this model in a similar way to previous chapters.\n",
        "\n",
        "For instance, we\n",
        "can feed it an example text identical to how we have done it in earlier chapters. For\n",
        "example, consider the following example text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xez0DrGTjEv",
        "outputId": "b9803c38-c086-411f-d3a6-3c5a83f68684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djYVohQ6TjEw"
      },
      "source": [
        "Then, we can pass the encoded token IDs to the model as usual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi7zxN8aTjEw",
        "outputId": "45f554d7-2070-4f86-aa10-cc434fbbabde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outputs:\n",
            " tensor([[[-1.5854,  0.9904],\n",
            "         [-3.7235,  7.4548],\n",
            "         [-2.2661,  6.6049],\n",
            "         [-3.5983,  3.9902]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "\n",
        "print(\"Outputs:\\n\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN7aPZbVTjEw"
      },
      "source": [
        "In earlier chapters, a similar input would have produced an output tensor of [1, 4, 50257],\n",
        "where 50,257 represents the vocabulary size.\n",
        "\n",
        "As in previous chapters, the number of\n",
        "output rows corresponds to the number of input tokens (in this case, 4).\n",
        "\n",
        "However, each\n",
        "output's embedding dimension (the number of columns) is now reduced to 2 instead of\n",
        "50,257 since we replaced the output layer of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vvjz7om-TjEw"
      },
      "source": [
        "Remember that we are interested in finetuning this model so that it returns a class label\n",
        "that indicates whether a model input is spam or not spam.\n",
        "\n",
        "To achieve this, we don't need to\n",
        "finetune all 4 output rows but can focus on a single output token.\n",
        "\n",
        "In particular, we will\n",
        "focus on the last row corresponding to the last output token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHwNGKxETjEw"
      },
      "source": [
        "To extract the last output token, illustrated in figure 6.11, from the output tensor, we\n",
        "use the following code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYwyJQ-aTjEw",
        "outputId": "f3d85197-50f0-4e7e-abce-cc8822c5e11e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last output token: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ],
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DToGXKk3TjEw"
      },
      "source": [
        "Having modified the model, the next section will detail the process of transforming the\n",
        "last token into class label predictions and calculate the model's initial prediction accuracy.\n",
        "\n",
        "Following this, we will finetune the model for the spam classification task in the subsequent\n",
        "section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpqsxLXpTjEx"
      },
      "source": [
        "## **CALCULATING THE CLASSIFICATION LOSS AND ACCURACY**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYe7SElNTjEx"
      },
      "source": [
        "So far in this chapter, we have prepared the dataset, loaded a pretrained model, and\n",
        "modified it for classification-finetuning.\n",
        "           \n",
        "Before we proceed with the finetuning itself, only\n",
        "one small part remains: implementing the model evaluation functions used during\n",
        "finetuning,  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrgLyxMlTjEx"
      },
      "source": [
        "Before implementing the evaluation utilities, let's briefly discuss how we convert the model\n",
        "outputs into class label predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVs971rOTjEx"
      },
      "source": [
        "In the previous chapter, we computed the token ID of the next token generated by the\n",
        "LLM by converting the 50,257 outputs into probabilities via the softmax function and then\n",
        "returning the position of the highest probability via the argmax function.\n",
        "\n",
        "In this chapter, we\n",
        "take the same approach to calculate whether the model outputs a \"spam\" or \"not spam\"\n",
        "prediction for a given input, with the only difference being that we\n",
        "work with 2-dimensional instead of 50,257-dimensional outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIvvOG3sTjEx"
      },
      "source": [
        "Let's consider the last token output from\n",
        "the previous section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPTeXtLXTjEx",
        "outputId": "c97839fc-c104-4f3f-ecc0-584e6b826550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last output token: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ],
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6-WvSbETjEx"
      },
      "source": [
        "We can obtain the class label via the following code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tjNMC2oTjEx",
        "outputId": "963ddc40-63a9-4bbf-bf3a-d2f477c440b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class label: 1\n"
          ]
        }
      ],
      "source": [
        "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
        "label = torch.argmax(probas)\n",
        "print(\"Class label:\", label.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hCquyozTjEx"
      },
      "source": [
        "In this case, the code returns 1, meaning the model predicts that the input text is \"spam.\"\n",
        "\n",
        "Using the softmax function here is optional because the largest outputs directly correspond\n",
        "to the highest probability scores.\n",
        "\n",
        "Hence, we can simplify the\n",
        "code as follows, without using softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VwL7XbPTjEx",
        "outputId": "dec4ff2a-2e4a-446f-c913-a0e3683b434b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class label: 1\n"
          ]
        }
      ],
      "source": [
        "logits = outputs[:, -1, :]\n",
        "label = torch.argmax(logits)\n",
        "print(\"Class label:\", label.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6Ri2h3eTjEy"
      },
      "source": [
        "his concept can be used to compute the so-called classification accuracy, which measures\n",
        "the percentage of correct predictions across a dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjQPVPMjTjEy"
      },
      "source": [
        "to determine the classification accuracy, we apply the argmax-based prediction code to\n",
        "all examples in the dataset and calculate the proportion of correct predictions by defining a\n",
        "calc_accuracy_loader function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t7Push2TjEy"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    \"\"\"\n",
        "    Calculate the accuracy of a model on data provided by a DataLoader.\n",
        "\n",
        "    Args:\n",
        "        data_loader (torch.utils.data.DataLoader): DataLoader containing input and target batches.\n",
        "        model (torch.nn.Module): Trained model to evaluate.\n",
        "        device (torch.device): Device to run the model on ('cpu' or 'cuda').\n",
        "        num_batches (int, optional): Number of batches to evaluate.\n",
        "                                     If None, all batches are used.\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy of the model on the given data (range: 0.0 to 1.0).\n",
        "    \"\"\"\n",
        "\n",
        "    # Set the model to evaluation mode — disables dropout, batchnorm updates, etc.\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize counters for correct predictions and total samples\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    # Determine how many batches to iterate through\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Ensure we don't exceed total available batches\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    # Iterate through the DataLoader\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "\n",
        "        # Process only the specified number of batches\n",
        "        if i < num_batches:\n",
        "            # Move input and target tensors to the appropriate device\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            # Disable gradient calculations for faster evaluation\n",
        "            with torch.no_grad():\n",
        "                # Forward pass through the model\n",
        "                # Extract logits (model outputs before softmax)\n",
        "                # [:, -1, :] means we take the logits of the last token (useful in autoregressive models)\n",
        "                logits = model(input_batch)[:, -1, :]\n",
        "\n",
        "            # Get the predicted label (index of max logit value)\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            # Update counters\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            # Stop if we've reached the desired number of batches\n",
        "            break\n",
        "\n",
        "    # Compute and return the accuracy\n",
        "    return correct_predictions / num_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSJXLNJlTjEy"
      },
      "source": [
        "Let's use the function to determine the classification accuracies across various datasets\n",
        "estimated from 10 batches for efficiency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx5-Td8STjEy",
        "outputId": "8c302fc8-8ff4-467d-b627-1a5a658fa2ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 46.25%\n",
            "Validation accuracy: 45.00%\n",
            "Test accuracy: 48.75%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
        "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "#print(f\"Running on {device} device.\")\n",
        "\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
        "\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBr4LNd2TjEy"
      },
      "source": [
        "As we can see, the prediction accuracies are near a random prediction, which would be\n",
        "50% in this case.\n",
        "\n",
        "To improve the prediction accuracies, we need to finetune the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXhoMBvdTjEy"
      },
      "source": [
        "Classification accuracy is not a differentiable function, so we use cross entropy\n",
        "loss as a proxy to maximize accuracy.\n",
        "\n",
        "This is the same cross entropy loss discussed earlier.\n",
        "\n",
        "Accordingly, the calc_loss_batch function remains the same as in earlier, with one\n",
        "adjustment: we focus on optimizing only the last token, model(input_batch)[:, -1, :],\n",
        "rather than all tokens, model(input_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U7BO3GkTjEz"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17DqOgQuTjEz"
      },
      "source": [
        "We use the calc_loss_batch function to compute the loss for a single batch obtained from\n",
        "the previously defined data loaders. To calculate the loss for all batches in a data loader, we\n",
        "define the calc_loss_loader function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETN3Tyc7TjEz"
      },
      "outputs": [],
      "source": [
        "# Same as in chapter 5\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3H1QyJ_TjEz"
      },
      "source": [
        "Similar to calculating the training accuracy, we now compute the initial loss for each\n",
        "data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9BhlCeHTjEz",
        "outputId": "38651f8b-1454-49a9-8403-37979e13ed06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 2.453\n",
            "Validation loss: 2.583\n",
            "Test loss: 2.322\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJlS2Nf_TjEz"
      },
      "source": [
        "In the next section, we will implement a training function to finetune the model, which\n",
        "means adjusting the model to minimize the training set loss.\n",
        "\n",
        "Minimizing the training set\n",
        "loss will help increase the classification accuracy, our overall goal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjPAqoEFTjEz"
      },
      "source": [
        "## **FINETUNING THE MODEL ON SUPERVISED DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qM1XFZJTjEz"
      },
      "source": [
        "In this section, we define and use the training function to finetune the pretrained LLM and\n",
        "improve its spam classification accuracy.\n",
        "    \n",
        "The training loop is the\n",
        "same overall training loop we used earlier, with the only difference being that we\n",
        "calculate the classification accuracy instead of generating a sample text for evaluating the\n",
        "model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQW0og3sTjEz"
      },
      "source": [
        "The training function also closely mirrors\n",
        "the train_model_simple function used for pretraining the model earlier.\n",
        "                                    \n",
        "The only two distinctions are that we now track the number of training examples seen\n",
        "(examples_seen) instead of the number of tokens, and we calculate the accuracy after each\n",
        "epoch instead of printing a sample text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZMIJYHpTjEz"
      },
      "source": [
        "  \n",
        "Step 1: Set model to training mode\n",
        "\n",
        "Step 2: Reset loss gradients from previous batch iteration\n",
        "\n",
        "Step 3: Calculate loss gradients\n",
        "\n",
        "Step 4: Update model weights using loss gradients\n",
        "\n",
        "Step 5: New: track examples instead of tokens\n",
        "\n",
        "Step 6: Optional evaluation step\n",
        "\n",
        "Step 7: Calculate accuracy after each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObSHWxsaTjE0"
      },
      "outputs": [],
      "source": [
        "# Overall the same as `train_model_simple` in chapter 5\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                            eval_freq, eval_iter):\n",
        "    # Initialize lists to track losses and examples seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C07uAyvDTjE0"
      },
      "source": [
        "The evaluate_model function used in the train_classifier_simple is the same as the one we used earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3QJyCRuTjE0"
      },
      "outputs": [],
      "source": [
        "# Same as chapter 5\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUiXrETmTjE0"
      },
      "source": [
        "Next, we initialize the optimizer, set the number of training epochs, and initiate the training\n",
        "using the train_classifier_simple function.\n",
        "\n",
        "We will discuss the choice of the the number\n",
        "of training epochs after we evaluated the results.\n",
        "\n",
        "The training takes about 6 minutes on an\n",
        "M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soTFxslITjE0",
        "outputId": "6501d81c-19c3-4bb9-afd0-138cdc153627"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
            "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
            "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
            "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
            "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
            "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
            "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
            "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
            "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
            "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
            "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training completed in 8.83 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oSi4CGGTjE1"
      },
      "source": [
        "We then use matplotlib to plot the loss function for the training and\n",
        "validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnQbdUIMTjE1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for examples seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWSPuyDXTjE1",
        "outputId": "b9087ce1-bf4f-4517-8d02-875905b587d8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_9tSmPQTjE1"
      },
      "source": [
        "As we can see based on the sharp downward slope, the model is learning well\n",
        "from the training data, and there is little to no indication of overfitting; that is, there is no\n",
        "noticeable gap between the training and validation set losses)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSsiTo3STjE1"
      },
      "source": [
        "Using the same plot_values function, let's now also plot the classification accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVnOr3vITjE1",
        "outputId": "74247e7b-778c-47cc-a3aa-ce1951254c0a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dA7afwcTjE1"
      },
      "source": [
        "Based on the accuracy plot in figure , the model achieves a relatively high training and\n",
        "validation accuracy after epochs 4 and 5.\n",
        "    \n",
        "However, it's important to note that we previously set eval_iter=5 when using the\n",
        "train_classifier_simple function, which means our estimations of training and\n",
        "validation performance were based on only 5 batches for efficiency during training.\n",
        "\n",
        "Now, we will calculate the performance metrics for the training, validation, and test sets\n",
        "across the entire dataset by running the following code, this time without defining the\n",
        "eval_iter value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfrFGcXvTjE2",
        "outputId": "8ca25b53-ac26-4fc4-d07e-ae02afcd2404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 97.21%\n",
            "Validation accuracy: 97.32%\n",
            "Test accuracy: 95.67%\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgSCEr6aTjE2"
      },
      "source": [
        "The training and test set performances are almost identical.\n",
        "\n",
        "A slight discrepancy between the training and test set accuracies suggests minimal\n",
        "overfitting of the training data.\n",
        "\n",
        "Typically, the validation set accuracy is somewhat higher\n",
        "than the test set accuracy because the model development often involves tuning\n",
        "hyperparameters to perform well on the validation set, which might not generalize as\n",
        "effectively to the test set.\n",
        "\n",
        "This situation is common, but the gap could potentially be minimized by adjusting the\n",
        "model's settings, such as increasing the dropout rate (drop_rate) or the weight_decay\n",
        "parameter in the optimizer configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhXrEcHxTjE2"
      },
      "source": [
        "## **USING THE LLM AS A SPAM CLASSIFIER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vrz-NPMmTjE2"
      },
      "source": [
        "After finetuning and evaluating the model in the previous sections, we are now in the final\n",
        "stage of this chapter:  using the model to classify spam\n",
        "messages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bRUNj5qTjE2"
      },
      "source": [
        "Finally, let's use the finetuned GPT-based spam classification model.\n",
        "\n",
        "The following\n",
        "`classify_review function` follows data preprocessing steps similar to those we used in the\n",
        "SpamDataset implemented earlier in this chapter.\n",
        "\n",
        "And then, after processing text into token\n",
        "IDs, the function uses the model to predict an integer class label, similar to what we have\n",
        "implemented earlier, and then returns the corresponding class name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz9vZv4ETjE2"
      },
      "source": [
        "Step 1: Prepare inputs to the model\n",
        "\n",
        "Step 2: Truncate sequences if they too long\n",
        "    \n",
        "Step 3: Pad sequences to the longest sequence\n",
        "\n",
        "Step 4: Add batch dimension\n",
        "\n",
        "Step 5: Model inference without gradient tracking\n",
        "    \n",
        "Step 6: Logits of the last output token\n",
        "\n",
        "Step 7: Return the classified result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1P2aPitTjE2"
      },
      "outputs": [],
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare inputs to the model\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = model.pos_emb.weight.shape[0]\n",
        "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
        "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
        "\n",
        "    # Truncate sequences if they too long\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "\n",
        "    # Pad sequences to the longest sequence\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Return the classified result\n",
        "    return \"spam\" if predicted_label == 1 else \"not spam\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDlkcxe9TjE2"
      },
      "source": [
        "Let's try this classify_review function on an example text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOiPIxKKTjE3",
        "outputId": "941f869a-a3cc-4ace-b8ac-0c6144f6dd66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spam\n"
          ]
        }
      ],
      "source": [
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKZtGaggTjE3"
      },
      "source": [
        "The resulting model correctly predicts \"spam\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCc-GrZxTjE3",
        "outputId": "f795710d-91b6-4a08-f11c-71fcc9dd4e0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "not spam\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Hey, just wanted to check if we're still on\"\n",
        "    \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nxHEeTQTjE3"
      },
      "source": [
        "Also, here, the model makes a correct prediction and returns a \"not spam\" label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcOfhLlDTjE3"
      },
      "source": [
        "Finally, let's save the model in case we want to reuse the model later without having to\n",
        "train it again using the torch.save method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnMinNw7TjE3"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"review_classifier.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1DeUJVdTjE3"
      },
      "source": [
        "Once saved, the model can be loaded as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8umFX-AvTjE3",
        "outputId": "1d9db4c9-b0bd-467d-d975-8590aaf9635e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 285,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_state_dict = torch.load(\"review_classifier.pth\")\n",
        "model.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5iIGFImTjE3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONwvlOSwevPG"
      },
      "source": [
        "# **INSTRUCTION FINE-TUNING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDYGr1-CevPG"
      },
      "source": [
        "## **STEP 1: PREPARING DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc6DrRl9evPH"
      },
      "source": [
        "In this section, we download and format the instruction dataset for instruction finetuning a\n",
        "pretrained LLM in this chapter. The dataset consists of 1100 instruction-response pairs.\n",
        "\n",
        "The following code implements and executes a function to download this dataset, which\n",
        "is a relatively small file, only 204 KB in size, in JSON format. JSON, or JavaScript Object\n",
        "Notation, mirrors the structure of Python dictionaries, providing a simple structure for data\n",
        "interchange that is both human-readable and machine-friendly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS_z3SyLevPH",
        "outputId": "53368678-713a-401d-e071-d133d69d6391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "import ssl\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "    ssl_context = ssl.create_default_context()\n",
        "    ssl_context.check_hostname = False\n",
        "    ssl_context.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "    else:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            text_data = file.read()\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9Oq2JWbevPH"
      },
      "source": [
        "The data list , which we loaded from the JSON file contains the 1100 entries of the\n",
        "instruction dataset.\n",
        "\n",
        "Let's print one of the entries to see how each entry is structured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEEk0jilevPH",
        "outputId": "fea6e93c-7933-404e-a7d1-23f2aa1c486e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilwq90yUevPH",
        "outputId": "3480d6ad-39a4-4796-a349-3437930c36a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Another example entry:\n",
            " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"Another example entry:\\n\", data[999])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-nF1-CXevPH"
      },
      "source": [
        "### **CONVERTING INSTRUCTIONS INTO ALPACA FORMAT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI1UlZmeevPI"
      },
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeOUJyo2evPI"
      },
      "source": [
        "This format_input function takes a dictionary entry as input and constructs a formatted\n",
        "string."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AESPyEzhevPI"
      },
      "source": [
        "Let's test it to dataset entry data[50], which to looked at earlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlY9vzAKevPI",
        "outputId": "97135394-6816-4fc3-e58d-d1bef9d25d56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pZ_pkRBevPI"
      },
      "source": [
        "Note that the format_input skips the optional ### Input: section if the 'input' field is\n",
        "empty, which we can test out by applying the format_input function to entry data[999]\n",
        "that we inspected earlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjI2NfqKevPI",
        "outputId": "3443e7db-2fff-4e4e-f77d-5e902fe3eadb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is an antonym of 'complicated'?\n",
            "\n",
            "### Response:\n",
            "An antonym of 'complicated' is 'simple'.\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[999])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8YAcSYmevPI"
      },
      "source": [
        "### **SPLITTING DATASET INTO TRAIN-TEST-VALIDATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpypHbJqevPJ"
      },
      "outputs": [],
      "source": [
        "train_portion = int(len(data) * 0.85)  # 85% for training\n",
        "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
        "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIv34IJuevPJ",
        "outputId": "2068369e-b96d-4dd6-a0c3-0afcdbe06ee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ],
      "source": [
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBSRetB0evPJ"
      },
      "source": [
        "Having successfully downloaded and partitioned the dataset, and gained a clear\n",
        "understanding of the dataset prompt formatting, we are now ready for the core\n",
        "implementation of the instruction finetuning process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAiRZg9EevPJ"
      },
      "source": [
        "## **STEP 2: ORGANIZING DATA INTO TRAINING BATCHES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5NV2yEWevPJ"
      },
      "source": [
        "In the previous chapter, the training batches were created automatically by the PyTorch\n",
        "DataLoader class, which employs a default collate function to combine lists of samples into\n",
        "batches.\n",
        "\n",
        "A collate function is responsible for taking a list of individual data samples and\n",
        "merging them into a single batch that can be processed efficiently by the model during\n",
        "training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5tAY9dYevPJ"
      },
      "source": [
        "However, the batching process for instruction finetuning in this chapter is a bit more\n",
        "involved and requires us to create our own custom collate function that we will later plug\n",
        "into the DataLoader.\n",
        "\n",
        "We implement this custom collate function to handle the specific\n",
        "requirements and formatting of our instruction finetuning dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmK2cdKBevPJ"
      },
      "source": [
        "First, we code an\n",
        "InstructionDataset class that applies format_input from the previous section and pretokenizes all inputs in the dataset, similar to the SpamDataset in chapter 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bJymcUWevPK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVwFmAF7evPK"
      },
      "source": [
        "Similar to the approach in chapter 6, we aim to accelerate training by collecting multiple\n",
        "training examples in a batch, which necessitates padding all inputs to a similar length.\n",
        "\n",
        "As with the previous chapter, we use the <|endoftext|> token as a padding token.\n",
        "    \n",
        "Instead of appending the <|endoftext|> tokens to the text inputs, we can append its\n",
        "token ID to the pre-tokenized inputs directly.\n",
        "\n",
        "To remind us which token ID we should use,\n",
        "we can use the tokenizer's .encode method on an <|endoftext|> token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K897P3uevPK",
        "outputId": "8bfe6e46-6569-486b-9add-f4d332238760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkY7eENoevPK"
      },
      "source": [
        "In previuosly, we padded all examples in a dataset to the same length.\n",
        "\n",
        "Moving on, here, we adopt a more sophisticated approach by developing a custom\n",
        "collate function that we can pass to the data loader.\n",
        "\n",
        "This custom collate function pads the\n",
        "training examples in each batch to have the same length, while allowing different batches\n",
        "to have different lengths.\n",
        "\n",
        "This approach minimizes unnecessary\n",
        "padding by only extending sequences to match the longest one in each batch, not the\n",
        "whole dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIt_7PsxevPK"
      },
      "source": [
        "We can implement the padding process with a custom collate\n",
        "function as follows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXc7tvEJevPK"
      },
      "source": [
        "Step 1: Find the longest sequence in the batch\n",
        "    \n",
        "Step 2: Pad and prepare inputs\n",
        "    \n",
        "Step 3: Remove extra padded token added earlier\n",
        "\n",
        "Step 4: Convert list of inputs to tensor and transfer to target device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItoDVW9FevPK"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_1(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    # and increase the max length by +1, which will add one extra\n",
        "    # padding token below\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst = []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to batch_max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        # Via padded[:-1], we remove the extra padded token\n",
        "        # that has been added via the +1 setting in batch_max_length\n",
        "        # (the extra padding token will be relevant in later codes)\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01CD_O_eevPL"
      },
      "source": [
        "The custom_collate_draft_1 we implemented is designed to be integrated into a PyTorch\n",
        "DataLoader, but it can also function as a standalone tool.\n",
        "\n",
        "Here, we use it independently to\n",
        "test and verify that it operates as intended."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaahLO7fevPL"
      },
      "source": [
        "Let's try it on three different inputs that we\n",
        "want to assemble into a batch, where each example gets padded to the same length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRJwfA4FevPL",
        "outputId": "20162442-b8a3-4a7b-cdb9-16fe224be1b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_draft_1(batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeaUYR8EevPL"
      },
      "source": [
        "As we can see based on the preceding output, all inputs have been padded to the length of\n",
        "the longest input list, inputs_1 containing 5 token IDs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLlaBpNaevPL"
      },
      "source": [
        "So far, we have just implemented our first custom collate function to create batches from\n",
        "lists of inputs.\n",
        "\n",
        "However, as you learned in previous lessons, we also need to create batches\n",
        "with the target token IDs, corresponding to the batch of input IDs.\n",
        "\n",
        "These target IDs are crucial because they represent what we want the model to\n",
        "generate and what we need during training to calculate the loss for the weight updates,\n",
        "similar to previous chapters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfpzQ0VUevPM"
      },
      "source": [
        "#### **CREATING TARGET TOKEN IDS FOR TRAINING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-4L0RV_evPM"
      },
      "source": [
        "Similar to the process described for pretraining an LLM, the target token IDs\n",
        "match the input token IDs but are shifted one position to the right.\n",
        "\n",
        "This setup allows the LLM to learn how to predict the next token in a sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFtHQZo9evPM"
      },
      "source": [
        "The following updated collate function generates the target token IDs from the input token IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeluXVe0evPM"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_2(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fey7u5vievPM"
      },
      "source": [
        "Step 1: Truncate the last token for inputs\n",
        "                               \n",
        "Step 2: Shift +1 to the right for targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK718JBPevPM",
        "outputId": "82ca306d-514d-4a84-926e-ef7bedebd2cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lwNB2n-evPM"
      },
      "source": [
        "The 1st tensor represents inputs.\n",
        "    \n",
        "The 2nd tensor represents the targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM1TICUUevPN"
      },
      "source": [
        "In the next step, we assign a -100 placeholder value to all padding tokens.\n",
        "\n",
        "This special value allows us to exclude these padding tokens from contributing to\n",
        "the training loss calculation, ensuring that only meaningful data influences model learning.\n",
        "\n",
        "In classification fine-tuning, we did not have to worry about this since we only trained the model based on\n",
        "the last output token.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYzCvfg1evPN"
      },
      "source": [
        "Note that we retain one end-of-text token, ID 50256, in the target list.\n",
        "\n",
        "This allows the LLM to learn when to generate an end-of-text token\n",
        "in response to instructions, which we use as an indicator that the generated response is\n",
        "complete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwatDjDLevPN"
      },
      "source": [
        "In the following code, we modify our custom collate function to replace tokens with ID\n",
        "50256 with -100 in the target lists.\n",
        "\n",
        "Additionally, we introduce\n",
        "an allowed_max_length parameter to optionally limit the length of the samples.\n",
        "\n",
        "This\n",
        "adjustment will be useful if you plan to work with your own datasets that exceed the 1024-\n",
        "token context size supported by the GPT-2 model.\n",
        "\n",
        "The code for this updated collate function\n",
        "is as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByRp7t72evPN"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hECufIGxevPN"
      },
      "source": [
        "Step 1: Replace all but the first padding tokens in targets by ignore_index\n",
        "\n",
        "Step 2: Optionally truncate to maximum sequence length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9RcPRZGevPO"
      },
      "source": [
        "Again, let's try the collate function on the sample batch that we created earlier to check\n",
        "that it works as intended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK-beFshevPO",
        "outputId": "4bbb13d9-3214-4928-a308-f8222f2afb9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdlNbJYCevPO"
      },
      "source": [
        "The modified collate function works as expected, altering the target list by inserting the\n",
        "token ID -100.\n",
        "\n",
        "What is the logic behind this adjustment? Let's explore the underlying\n",
        "purpose of this modification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdww6qDievPO"
      },
      "source": [
        "For demonstration purposes, consider the following simple and self-contained example\n",
        "where each output logit can correspond to a potential token from the model's vocabulary.\n",
        "\n",
        "Here's how we might calculate the cross entropy loss (introduced in chapter 5) during\n",
        "training when the model predicts a sequence of tokens, similar to what we have done in\n",
        "chapter 5 when pretraining the model, or in chapter 6 when finetuning the model for\n",
        "classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPjH1t4fevPO",
        "outputId": "473fd75a-3997-431d-de6d-56e4672e7ae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.1269)\n"
          ]
        }
      ],
      "source": [
        "logits_1 = torch.tensor(\n",
        "    [[-1.0, 1.0],  # 1st training example\n",
        "     [-0.5, 1.5]]  # 2nd training example\n",
        ")\n",
        "targets_1 = torch.tensor([0, 1])\n",
        "\n",
        "\n",
        "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
        "print(loss_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkazlkq-evPO"
      },
      "source": [
        "Adding an additional token ID will, as we would expect, affect the loss calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhLjUwqRevPO",
        "outputId": "4c65d05c-c452-46df-84a2-286d2c3cc5b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.7936)\n"
          ]
        }
      ],
      "source": [
        "logits_2 = torch.tensor(\n",
        "    [[-1.0, 1.0],\n",
        "     [-0.5, 1.5],\n",
        "     [-0.5, 1.5]]  # New 3rd training example\n",
        ")\n",
        "targets_2 = torch.tensor([0, 1, 1])\n",
        "\n",
        "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
        "print(loss_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SuS0NyNevPP"
      },
      "source": [
        "Now, let's get to the interesting part and see what happens if we replace the third target\n",
        "token ID with -100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWfbGoB6evPP",
        "outputId": "b0400275-2284-4aa9-e9e6-4e87b2b4284c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.1269)\n",
            "loss_1 == loss_3: tensor(True)\n"
          ]
        }
      ],
      "source": [
        "logits_2 = torch.tensor(\n",
        "    [[-1.0, 1.0],\n",
        "     [-0.5, 1.5],\n",
        "     [-0.5, 1.5]]  # New 3rd training example\n",
        ")\n",
        "\n",
        "targets_3 = torch.tensor([0, 1, -100])\n",
        "\n",
        "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
        "print(loss_3)\n",
        "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBLcfCRyevPP"
      },
      "source": [
        "Based on this result, we can see that the resulting loss on these 3 training examples is\n",
        "identical to the loss we calculated from the 2 training examples earlier.\n",
        "\n",
        "In other words, the\n",
        "cross entropy loss function ignored the third entry in the targets_3 vector, the token ID\n",
        "corresponding to -100.\n",
        "\n",
        "(Interested readers can try to replace the -100 value with another\n",
        "token IDs that is not 0 or 1, and will see that this results in an error.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7haxfdtevPP"
      },
      "source": [
        "So, what's so special about -100 that it's ignored by the cross entropy loss? The default\n",
        "setting of the cross entropy function in PyTorch is cross_entropy(...,\n",
        "ignore_index=-100).\n",
        "\n",
        "This means that it ignores targets labeled with -100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyLgf4aoevPP"
      },
      "source": [
        "In this chapter, we take advantage of this ignore_index to ignore the additional end-oftext (padding) tokens that we used to pad the training examples to have the same length in\n",
        "each batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6Z4ayoqevPP"
      },
      "source": [
        "However, we want to keep one 50256 (end-of-text)\n",
        "token ID in the targets because it helps the LLM to learn to generate end-of-text tokens,\n",
        "which we can use as an indicator that a response is complete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXiP8vYBevPP"
      },
      "source": [
        "#### **MASKING TARGET TOKEN IDS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2YabLJbevPP"
      },
      "source": [
        "In addition to masking out padding tokens, it is also common to mask out the target\n",
        "token IDs that correspond to the instruction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa1PA1M5evPQ"
      },
      "source": [
        "By masking out the target token IDs that correspond to the instruction, the LLM cross entropy loss is only computed for the generated response target\n",
        "IDs.\n",
        "\n",
        "By masking out the instruction tokens, the model is trained to focus on generating\n",
        "accurate responses rather than additionally also memorizing instructions, which can help\n",
        "with reducing overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bobP8UCpevPQ"
      },
      "source": [
        "\n",
        "Currently, researchers are divided on whether masking the instructions is universally beneficial during instruction finetuning.\n",
        "\n",
        "For instance, a recent\n",
        "paper titled \"Instruction Tuning With Loss Over Instructions\" demonstrated that not\n",
        "masking the instructions benefits the LLM performance.\n",
        "\n",
        "In this chapter, we do not apply masking and leave it as an optional\n",
        "exercise for the reader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exsW8g8qevPQ"
      },
      "source": [
        "## **STEP 3: CREATING DATALOADERS FOR AN INSTRUCTION DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJt1SrZRevPQ"
      },
      "source": [
        "The custom_collate_fn includes code to move the input and target tensors (for\n",
        "example, torch.stack(inputs_lst).to(device)) to a specified device, which can be\n",
        "either \"cpu\" or \"cuda\" (for GPUs), or optionally \"mps\" for Macs with Apple Silicon chips.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Dgoc5wevPQ"
      },
      "source": [
        "In previous chapters, we moved the data onto the target device (for example, the GPU\n",
        "memory when device=\"cuda\") in the main training loop. Having this as part of the collate\n",
        "function offers the advantage of performing this device transfer process as a background\n",
        "process outside the training loop, preventing it from blocking the GPU during model\n",
        "training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZtE4sguevPQ"
      },
      "source": [
        "The following code initializes the device variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwXf3YnlevPQ",
        "outputId": "fe60bdda-569a-4ebb-9970-34c9eced3f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# However, the resulting loss values may be slightly different.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1bnMsnAevPR"
      },
      "source": [
        "Next, to reuse the chosen device setting in custom_collate_fn when we plug it into the\n",
        "PyTorch DataLoader class later in this section, we use the partial function from Python's\n",
        "functools standard library to create a new version of the function with the device\n",
        "argument pre-filled.\n",
        "\n",
        "Additionally, we set the allowed_max_length to 1024, which truncates\n",
        "the data to the maximum context length supported by the GPT-2 model we finetune later in\n",
        "this chapter:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edkhHB4GevPR"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFeTgmRcevPT"
      },
      "source": [
        "Next, we can set up the data loaders as we did in previous chapters, but this time we will\n",
        "use our custom collate function for the batching process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-OP4CMKevPT"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpzepq4PevPT"
      },
      "source": [
        "Let's examine the dimensions of the input and target batches generated by the training\n",
        "loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtbbOU8levPT",
        "outputId": "831156fb-2f81-4a86-a726-8271b6e787ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_lfEDWlevPT"
      },
      "source": [
        "In the preceding output, we can see that the first input and target batch have dimensions\n",
        "8×61, where 8 represents the batch size, and 61 is the number of tokens in each training\n",
        "example in this batch.\n",
        "\n",
        "The second input and target batch have a different number of\n",
        "tokens, for instance, 76.\n",
        "\n",
        "\n",
        "As we saw in the preceding code output, thanks to our custom collate function, the data\n",
        "loader is able to create batches of different lengths.\n",
        "\n",
        "In the next section, we load a\n",
        "pretrained LLM that we can then finetune with this data loader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mszq0_7JevPU"
      },
      "source": [
        "## **STEP 4: LOADING A PRETRAINED LLM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3D0CTiqevPU"
      },
      "source": [
        "Before beginning instruction finetuning, we first load a pretrained GPT model,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-QRPj9yevPU"
      },
      "source": [
        "Instead of using the smallest 124 million\n",
        "parameter model as before, we load the medium-sized model with 355 million parameters.\n",
        "\n",
        "The reason for this choice is that the 124 million parameter model is too limited in capacity\n",
        "to achieve qualitatively satisfactory results via instruction finetuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33IL7e_WevPU"
      },
      "source": [
        "This is done using the same code as in section 5.5 of chapter 5 and section 6.4 of\n",
        "the previous chapter, except that we now specify \"gpt2-medium (355M)\" instead of \"gpt2-small\n",
        "(124M)\".\n",
        "\n",
        "Please note that executing the code provided below will initiate the download of\n",
        "the medium-sized GPT model, which has a storage requirement of approximately 1.42\n",
        "gigabytes.\n",
        "\n",
        "This is roughly three times larger than the storage space needed for the small\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXAEmz_qevPU",
        "outputId": "cad3052e-ae27-4036-9d16-f428eaea73f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/encoder.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/hparams.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
          ]
        }
      ],
      "source": [
        "from gpt_download3 import download_and_load_gpt2\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLHNM3WkevPU"
      },
      "source": [
        "Before diving into finetuning the model in the next section, let's take a moment to assess\n",
        "the pretrained LLM's performance on one of the validation tasks by comparing its output to\n",
        "the expected response.\n",
        "\n",
        "This will give us a baseline understanding of how well the model\n",
        "performs on an instruction-following task right out of the box, prior to finetuning, and will\n",
        "help us appreciate the impact of finetuning later on.\n",
        "\n",
        "We use the first example from the\n",
        "validation set for this assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKv8NReCevPV",
        "outputId": "6fba1957-910a-41bf-d74f-d993b4338e8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrh_v-82evPV"
      },
      "outputs": [],
      "source": [
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256,\n",
        ")\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNosYFq4evPV"
      },
      "source": [
        "It's important to note that the generate function returns the combined input and output\n",
        "text.\n",
        "\n",
        "This behavior was convenient in previous chapters since pretrained LLMs are primarily\n",
        "designed as text-completion models, where the input and output are concatenated to\n",
        "create a coherent and legible text.\n",
        "\n",
        "However, when evaluating the model's performance on a\n",
        "specific task, we often want to focus solely on the model's generated response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fditZoW0evPV"
      },
      "source": [
        "To isolate the model's response text, we need to subtract the length of the input\n",
        "instruction from the start of the `generated_text`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDcHSWG6evPV",
        "outputId": "9c9d3f58-2457-4bc6-ef97-e5bd6d4e0256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Response:\n",
            "\n",
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ],
      "source": [
        "response_text = generated_text[len(input_text):].strip()\n",
        "print(response_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uueXJhOevPV"
      },
      "source": [
        "This code snippet removes the input text from the beginning of the generated_text,\n",
        "leaving us with only the model's generated response. The strip() function is then applied\n",
        "to remove any leading or trailing whitespace characters. The output is as follows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aISD0YitevPW"
      },
      "source": [
        "As we can see from the output, the pretrained model is not yet capable of correctly\n",
        "following the given instruction.\n",
        "\n",
        "While it does create a \"Response\" section, it simply repeats\n",
        "the original input sentence and part of the instruction, failing to convert the active sentence\n",
        "to passive voice as requested.\n",
        "\n",
        "\n",
        "In the upcoming section, we implement the finetuning process to improve the model's\n",
        "ability to comprehend and appropriately respond to such requests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ijzEJtievPW"
      },
      "source": [
        "## **STEP 5: FINETUNING THE LLM ON INSTRUCTION DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0kOiYxoevPW"
      },
      "source": [
        "We already did all the hard work when we implemented the\n",
        "instruction dataset processing at the beginning of this chapter.\n",
        "\n",
        "For the finetuning process\n",
        "itself, we can reuse the loss calculation and training functions implemented in chapter 5\n",
        "during the pretraining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45cOW6xWevPW"
      },
      "source": [
        "Before we begin training, let's calculate the initial loss for the training and validation sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4FUxvEWevPW"
      },
      "source": [
        "#### **PREVIOUSLY DEFINED FUNCTIONS WHICH WE WILL REQUIRE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BFS1aQHevPW"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k3a90MTevPX",
        "outputId": "22447c60-e391-4918-e3bf-f5b66e6f6172"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 3.8258946418762205\n",
            "Validation loss: 3.7619189739227297\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oJ0Zs0kevPX"
      },
      "source": [
        "With the model and data loaders prepared, we can now proceed to train the model.\n",
        "\n",
        "The following code sets up the training process, including initializing the optimizer, setting the\n",
        "number of epochs, and defining the evaluation frequency and starting context to evaluate\n",
        "generated LLM responses during training based on the first validation set instruction\n",
        "(val_data[0]) we looked at earlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwHt1XGoevPX",
        "outputId": "5db4c353-11cb-4a07-f275-8a3bb644d0e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
            "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
            "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.945\n",
            "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
            "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
            "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
            "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
            "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
            "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
            "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.790\n",
            "Ep 1 (Step 000050): Train loss 0.662, Val loss 0.783\n",
            "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.764\n",
            "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
            "Ep 1 (Step 000065): Train loss 0.652, Val loss 0.735\n",
            "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
            "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.729\n",
            "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
            "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.709\n",
            "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
            "Ep 1 (Step 000095): Train loss 0.500, Val loss 0.681\n",
            "Ep 1 (Step 000100): Train loss 0.502, Val loss 0.677\n",
            "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
            "Ep 1 (Step 000110): Train loss 0.555, Val loss 0.667\n",
            "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.664\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
            "Training completed in 121.19 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhO2MjGUevPY"
      },
      "source": [
        "As we can see based on the outputs above, the model trains well, as we can tell based on the decreasing training loss and validation loss values.\n",
        "    \n",
        "Furthermore, based on the response text printed after each epoch, we can see that the model almost correctly follows the instruction to convert the input sentence 'The chef cooks the meal every day.' into passive voice 'The meal is prepared every day by the chef.' (We will properly format and evaluate the responses in a later section.\n",
        "\n",
        "To get better results, we need to finetune the model for more epochs.\n",
        "\n",
        "Finally, let's take a look at the training and validation loss curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD0uUAPNevPY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thUqMSF7evPY",
        "outputId": "1553ce56-1248-4f58-b293-e9f22f3bbc3a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3UFfa14evPY"
      },
      "source": [
        "As we can see in the loss plot shown above, the model's performance on both the\n",
        "training and validation sets improves substantially over the course of training.\n",
        "\n",
        "The rapid\n",
        "decrease in losses during the initial phase indicates that the model is quickly learning\n",
        "meaningful patterns and representations from the data. Then, as training progresses to the\n",
        "second epoch, the losses continue to decrease but at a slower rate, suggesting that the\n",
        "model is finetuning its learned representations and converging to a stable solution.\n",
        "\n",
        "\n",
        "While the loss plot in figure 7.17 indicates that the model is training effectively, the most\n",
        "crucial aspect is its performance in terms of response quality and correctness. In the\n",
        "remaining sections of this chapter, we will extract the responses and store them in a format\n",
        "that allows us to evaluate and quantify the response quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpzlZLlzevPY"
      },
      "source": [
        "## **STEP 6: EXTRACTING AND SAVING RESPONSES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jk340AWevPY"
      },
      "source": [
        "After finetuning the LLM on the training portion of the instruction dataset as described in\n",
        "the previous section, we now proceed to evaluate its performance on the held-out test set.\n",
        "    \n",
        "To accomplish this, we first extract the model-generated responses for each input in the\n",
        "test dataset and collect them for manual analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBh1X_ccevPY"
      },
      "source": [
        "Step 1: Iterate over the first 3 test set samples\n",
        "\n",
        "Step 2:  Use the generate function defined earlier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gA491e3evPY"
      },
      "source": [
        "As mentioned earlier, the generate function returns the combined input and output text, so\n",
        "we use slicing and the .replace() method on the generated_text contents to extract the\n",
        "model's response.\n",
        "\n",
        "The instructions, followed by the given test set response and model\n",
        "response are shown below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhgYVtQFevPZ",
        "outputId": "cedd9efd-4871-450e-d337-50c75bdfade6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> A thunderstorm is a type of cloud that typically forms in the atmosphere over a region of high pressure. It typically produces a strong wind that blows across the area, creating a dense, dense cloud.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is George Bernard Shaw.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        ")\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sirsTHO5evPZ"
      },
      "source": [
        "As we can see based on the test set instructions, given responses, and the model's\n",
        "responses, the model performs relatively well.\n",
        "\n",
        "The answers to the first instruction\n",
        "is clearly correct, while the second answer and the third answers are not correct.\n",
        "\n",
        "This is because we have done the fine-tuning for only 1 epoch due to hardware limitations. To get better results, we need to increase the epochs to at least 2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZwcGBYnevPZ"
      },
      "source": [
        "Most importantly, we can see that model evaluation is not as straightforward as in the\n",
        "previous chapter, where we simply calculated the percentage of correct spam/non-spam\n",
        "class labels to obtain the classification accuracy.\n",
        "\n",
        "In practice, instruction-finetuned LLMs\n",
        "such as chatbots are evaluated via multiple approaches:\n",
        "\n",
        "1. Short-answer and multiple choice benchmarks such as MMLU (\"Measuring\n",
        "Massive Multitask Language Understanding,\" https://arxiv.org/abs/2009.\n",
        "03300), which test the general knowledge of a model.\n",
        "\n",
        "2. Human preference comparison to other LLMs, such as LMSYS chatbot\n",
        "arena (https://arena.lmsys.org).\n",
        "\n",
        "3. Automated conversational benchmarks, where another LLM like GPT-4 is\n",
        "used to evaluate the responses, such as AlpacaEval (https://tatsulab.github.io/alpaca_eval/).\n",
        "completes the request."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDbamf4_evPZ"
      },
      "source": [
        "Considering the scale of the task at hand, we will implement an approach similar to\n",
        "method 3, which involves evaluating the responses automatically using another LLM.\n",
        "\n",
        "This\n",
        "will allow us to efficiently assess the quality of the generated responses without the need\n",
        "for extensive human involvement, thereby saving time and resources while still obtaining\n",
        "meaningful performance indicators."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19h794X1evPZ"
      },
      "source": [
        "To prepare the responses for this evaluation process, we append the generated model\n",
        "responses to the test_set dictionary and save the updated data as an \"instructiondata-with-response.json\" file for record keeping.\n",
        "\n",
        "Additionally, by saving this file, we can\n",
        "easily load and analyze the responses in separate Python sessions later on if needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_YahODGevPZ"
      },
      "source": [
        "The following code uses the generate method in the same manner as before; however,\n",
        "we now iterate over the entire test_set.\n",
        "\n",
        "Also, instead of printing the model responses, we\n",
        "add them to the test_set dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6qFrUMaevPZ",
        "outputId": "0d8f25af-b44b-443e-e339-18787747054f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 110/110 [18:28<00:00, 10.08s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1au4MxMevPa"
      },
      "source": [
        "Let's verify that the responses have been correctly added to the test_set dictionary by\n",
        "examining one of the entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6S7s3O1evPa",
        "outputId": "ca1a781c-7f7d-4a9c-e4ca-e781fc8b9393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
          ]
        }
      ],
      "source": [
        "print(test_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofGYFPAdevPa"
      },
      "source": [
        "Based on the output, we can see that the `model_response` has been added correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClnvNA_8evPa"
      },
      "source": [
        "\n",
        "Finally, we save the model as gpt2-medium355M-sft.pth file to be able to reuse it in future\n",
        "projects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhDaHsLKevPa",
        "outputId": "131b8cad-6265-4cf0-c7dd-f9d6701ef299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as gpt2-medium355M-sft.pth\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")\n",
        "\n",
        "# Load model via\n",
        "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxki87QHevPa"
      },
      "source": [
        "## **STEP 7: EVALUATING THE FINE-TUNED LLM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9q9tmNmevPa"
      },
      "source": [
        "Previously, we judged the performance of an instruction finetuned model by looking at its\n",
        "responses on 3 examples of the test set.\n",
        "\n",
        "While this gives us a rough idea of how well the\n",
        "model performs, this method does not really scale well to larger amounts of responses.\n",
        "\n",
        "So, in this section, we implement a method to automate the response evaluation of the finetuned LLM using another, larger LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezBHXSkpevPb"
      },
      "source": [
        "To implement the evaluation step which involves evaluating test set responses in\n",
        "an automated fashion, we utilize an existing instruction-finetuned 8 billion parameter Llama\n",
        "3 model developed by Meta AI.\n",
        "\n",
        "This model can be run locally using the open-source Ollama\n",
        "application (https://ollama.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9QXOJKPevPb"
      },
      "source": [
        "Ollama is an efficient application for running LLMs on a laptop.\n",
        "\n",
        "It serves as a wrapper\n",
        "around the open-source llama.cpp library (https://github.com/ggerganov/llama.cpp), which\n",
        "implements LLMs in pure C/C++ to maximize efficiency.\n",
        "\n",
        "However, note that Ollama is only\n",
        "a tool for generating text using LLMs (inference) and does not support training or finetuning\n",
        "LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z7AJUGkevPb"
      },
      "source": [
        "The following code verifies that the Ollama session is running properly before we use\n",
        "Ollama to evaluate the test set responses generated in the previous section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9vICa1vevPb",
        "outputId": "db4b5a69-38dd-4d8c-9121-ef3b187be049"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama running: True\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "\n",
        "def check_if_running(process_name):\n",
        "    running = False\n",
        "    for proc in psutil.process_iter([\"name\"]):\n",
        "        if process_name in proc.info[\"name\"]:\n",
        "            running = True\n",
        "            break\n",
        "    return running\n",
        "\n",
        "ollama_running = check_if_running(\"ollama\")\n",
        "\n",
        "if not ollama_running:\n",
        "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
        "print(\"Ollama running:\", check_if_running(\"ollama\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjdLjworevPb"
      },
      "source": [
        "An alternative to the ollama run command for interacting with the model is through its\n",
        "REST API using Python.\n",
        "\n",
        "The following query_model function demonstrates how to use the\n",
        "API:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoUNGJt-evPb"
      },
      "source": [
        "Step 1: Create the data payload as a dictionary\n",
        "    \n",
        "Step 2: Convert the dictionary to a JSON formatted string and encode it to bytes\n",
        "    \n",
        "Step 3: Create a request object, setting the method to POST and adding necessary headers\n",
        "    \n",
        "Step 4: Send the request and capture the response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swe4R5iXevPb"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "def query_model(\n",
        "    prompt,\n",
        "    model=\"llama3\",\n",
        "    url=\"http://localhost:11434/api/chat\"\n",
        "):\n",
        "    # Create the data payload as a dictionary\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"options\": {     # Settings below are required for deterministic responses\n",
        "            \"seed\": 123,\n",
        "            \"temperature\": 0,\n",
        "            \"num_ctx\": 2048\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
        "    payload = json.dumps(data).encode(\"utf-8\")\n",
        "\n",
        "    # Create a request object, setting the method to POST and adding necessary headers\n",
        "    request = urllib.request.Request(\n",
        "        url,\n",
        "        data=payload,\n",
        "        method=\"POST\"\n",
        "    )\n",
        "    request.add_header(\"Content-Type\", \"application/json\")\n",
        "\n",
        "    # Send the request and capture the response\n",
        "    response_data = \"\"\n",
        "    with urllib.request.urlopen(request) as response:\n",
        "        # Read and decode the response\n",
        "        while True:\n",
        "            line = response.readline().decode(\"utf-8\")\n",
        "            if not line:\n",
        "                break\n",
        "            response_json = json.loads(line)\n",
        "            response_data += response_json[\"message\"][\"content\"]\n",
        "\n",
        "    return response_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUMwO4s2evPc"
      },
      "source": [
        "Before running the subsequent code cells in this notebook, ensure that Ollama is still\n",
        "running. The previous code cells should print \"Ollama running: True\" to confirm that the\n",
        "model is active and ready to receive requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMCEkVPaevPc"
      },
      "source": [
        "Here's an example of how to use the `query_llama` function we just implemented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6AQDZR9evPc",
        "outputId": "42cfc549-1673-4b24-d15a-d98bb228e4f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
            "\n",
            "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
            "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
            "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
            "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
            "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and well-being.\n",
            "\n",
            "In the wild, llamas might also eat:\n",
            "\n",
            "1. Leaves: They'll munch on leaves from trees and shrubs, including plants like willow, alder, and birch.\n",
            "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or cottonwood.\n",
            "3. Mosses and lichens: These non-vascular plants can be a tasty snack for llamas.\n",
            "\n",
            "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
          ]
        }
      ],
      "source": [
        "model = \"llama3\"\n",
        "result = query_model(\"What do Llamas eat?\", model)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48v-31PtevPc"
      },
      "source": [
        "Using the query_model function defined earlier, we can evaluate the responses generated\n",
        "by our finetuned model with a prompt that prompts the Llama 3 model to rate our\n",
        "finetuned model's responses on a scale from 0 to 100 based on the given test set response\n",
        "as reference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LxVJc4wevPc"
      },
      "source": [
        "First, we apply this approach to the first three examples from the test set that we\n",
        "examined in a previous section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0EZr04WevPc",
        "outputId": "de7ec475-c66c-431c-f877-2f759cde09c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "\n",
            "Score:\n",
            ">> I'd rate the model response \"The car is as fast as a bullet.\" an 85 out of 100.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "* The response uses a simile correctly, comparing the speed of the car to something else (in this case, a bullet).\n",
            "* The comparison is relevant and makes sense, as bullets are known for their high velocity.\n",
            "* The phrase \"as fast as\" is used correctly to introduce the simile.\n",
            "\n",
            "The only reason I wouldn't give it a perfect score is that some people might find the comparison slightly less vivid or evocative than others. For example, comparing something to lightning (as in the original response) can be more dramatic and attention-grabbing. However, \"as fast as a bullet\" is still a strong and effective simile that effectively conveys the idea of the car's speed.\n",
            "\n",
            "Overall, I think the model did a great job!\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Dataset response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> A thunderstorm is a type of cloud that typically forms in the atmosphere over a region of high pressure. It typically produces a strong wind that blows across the area, creating a dense, dense cloud.\n",
            "\n",
            "Score:\n",
            ">> I'd score this model response as 20 out of 100.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "* The response doesn't directly answer the question about what type of cloud is typically associated with thunderstorms.\n",
            "* Instead, it provides a general description of thunderstorms, which is not relevant to the original question.\n",
            "* The response also contains some inaccuracies, such as stating that thunderstorms form over high pressure regions (thunderstorms can occur in various weather patterns).\n",
            "\n",
            "A good model response should directly answer the question, provide accurate and relevant information, and avoid unnecessary details. In this case, the response fails to meet these criteria, which is why I'd score it relatively low.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Dataset response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is George Bernard Shaw.\n",
            "\n",
            "Score:\n",
            ">> I'd rate this model response a 0 out of 100.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "* The correct answer is Jane Austen, not George Bernard Shaw.\n",
            "* George Bernard Shaw was an Irish playwright and author, but he did not write 'Pride and Prejudice'.\n",
            "* The response is completely incorrect and does not provide any relevant information about the actual author of the book.\n",
            "\n",
            "Therefore, I would give this model response a score of 0 out of 100.\n",
            "\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "for entry in test_data[:3]:\n",
        "    prompt = (\n",
        "        f\"Given the input `{format_input(entry)}` \"\n",
        "        f\"and correct output `{entry['output']}`, \"\n",
        "        f\"score the model response `{entry['model_response']}`\"\n",
        "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "    )\n",
        "    print(\"\\nDataset response:\")\n",
        "    print(\">>\", entry['output'])\n",
        "    print(\"\\nModel response:\")\n",
        "    print(\">>\", entry[\"model_response\"])\n",
        "    print(\"\\nScore:\")\n",
        "    print(\">>\", query_model(prompt))\n",
        "    print(\"\\n-------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl4eu_MrevPc"
      },
      "source": [
        "Based on the generated responses, we can observe that the Llama 3 model provides\n",
        "reasonable evaluations and is capable of assigning partial points when a model's answer is\n",
        "not entirely correct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzSkXwPjevPd"
      },
      "source": [
        "The previous prompt returns highly detailed evaluations in addition to the score.\n",
        "\n",
        "We can\n",
        "modify the prompt to just generate integer scores ranging from 0 to 100, where 100\n",
        "represents the best possible score.\n",
        "\n",
        "This modification allows us to calculate an average score\n",
        "for our model, which serves as a more concise and quantitative assessment of its\n",
        "performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQQut5eievPd"
      },
      "source": [
        "The following generate_model_scores function uses a modified the prompt telling the\n",
        "model to \"Respond with the integer number only.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MaqptV4evPd",
        "outputId": "ab953bec-b350-491f-9339-f18f9ee7fd99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "\n",
            "Score:\n",
            ">> 85\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Dataset response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> A thunderstorm is a type of cloud that typically forms in the atmosphere over a region of high pressure. It typically produces a strong wind that blows across the area, creating a dense, dense cloud.\n",
            "\n",
            "Score:\n",
            ">> 20\n",
            "\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "for entry in test_data[:2]:\n",
        "    prompt = (\n",
        "            f\"Given the input `{format_input(entry)}` \"\n",
        "            f\"and correct output `{entry['output']}`, \"\n",
        "            f\"score the model response `{entry['model_response']}`\"\n",
        "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "            f\"Respond with the integer number only.\"\n",
        "        )\n",
        "    score = query_model(prompt, model)\n",
        "    print(\"\\nDataset response:\")\n",
        "    print(\">>\", entry['output'])\n",
        "    print(\"\\nModel response:\")\n",
        "    print(\">>\", entry[\"model_response\"])\n",
        "    print(\"\\nScore:\")\n",
        "    print(\">>\", query_model(prompt, model))\n",
        "    print(\"\\n-------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_0VkRmzevPd"
      },
      "outputs": [],
      "source": [
        "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
        "    scores = []\n",
        "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
        "        prompt = (\n",
        "            f\"Given the input `{format_input(entry)}` \"\n",
        "            f\"and correct output `{entry['output']}`, \"\n",
        "            f\"score the model response `{entry[json_key]}`\"\n",
        "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "            f\"Respond with the integer number only.\"\n",
        "        )\n",
        "        score = query_model(prompt, model)\n",
        "        try:\n",
        "            scores.append(int(score))\n",
        "        except ValueError:\n",
        "            print(f\"Could not convert score: {score}\")\n",
        "            continue\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd1XWB0bevPd"
      },
      "source": [
        "I am not running the above function because of hardware limitations. I am using a Macbook Air 2020.\n",
        "\n",
        "It takes about 1 min  on a M3 Macbook Air."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PW1Kfg1evPd"
      },
      "source": [
        "When you run the above code, you will see that the evaluation output shows that our finetuned model achieves an average score above 50,\n",
        "which provides a useful benchmark for comparison against other models or for\n",
        "experimenting with different training configurations to improve the model's performance.\n",
        "\n",
        "It's worth noting that Ollama is not entirely deterministic at the time of this writing,\n",
        "which means that the scores you obtain might slightly vary from the ones presented above.\n",
        "    \n",
        "To obtain more robust results, you can repeat the evaluation multiple times and average\n",
        "the resulting scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4V1yJ9PevPd"
      },
      "source": [
        "To further improve our model's performance, we can explore various strategies, such as:\n",
        "\n",
        "(1) Adjusting the hyperparameters during finetuning, such as the learning\n",
        "rate, batch size, or number of epochs.\n",
        "\n",
        "\n",
        "(2) Increasing the size of the training dataset or diversifying the examples to\n",
        "cover a broader range of topics and styles.\n",
        "\n",
        "\n",
        "(3) Experimenting with different prompts or instruction formats to guide the\n",
        "model's responses more effectively.\n",
        "\n",
        "\n",
        "(4) Considering the use of a larger pretrained model, which may have greater\n",
        "capacity to capture complex patterns and generate more accurate\n",
        "responses.\n",
        "\n",
        "(5) We can also use parameter efficient fine-tuning techniques like LoRA.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdzTgIZPevPe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}